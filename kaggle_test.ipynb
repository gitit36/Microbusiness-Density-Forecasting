{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "PATH = '/Users/dh/Desktop/상진/kaggle/'\n",
    "\n",
    "# Load and prepare the data\n",
    "train_df = pd.read_csv(PATH+'train.csv')\n",
    "test_df = pd.read_csv(PATH+'test.csv')\n",
    "cs = pd.read_csv(PATH+'census_starter.csv')\n",
    "\n",
    "train_df = train_df.merge(cs, on=['cfips'])\n",
    "test_df = test_df.merge(cs, on=['cfips'])\n",
    "\n",
    "train_df['first_day_of_month'] = pd.to_datetime(train_df['first_day_of_month'])\n",
    "train_df['year'] = train_df['first_day_of_month'].dt.year\n",
    "train_df['month'] = train_df['first_day_of_month'].dt.month\n",
    "test_df['first_day_of_month'] = pd.to_datetime(test_df['first_day_of_month'])\n",
    "test_df['year'] = test_df['first_day_of_month'].dt.year\n",
    "test_df['month'] = test_df['first_day_of_month'].dt.month\n",
    "\n",
    "# Split the train data into train and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate the predictors and target variable\n",
    "X_train = train_df.drop(columns=['microbusiness_density', 'row_id', 'county', 'state', 'first_day_of_month', 'active'])\n",
    "y_train = train_df['microbusiness_density']\n",
    "X_val  = val_df.drop(columns=['microbusiness_density', 'row_id', 'county', 'state', 'first_day_of_month', 'active'])\n",
    "y_val  = val_df['microbusiness_density']\n",
    "X_test = test_df.drop(columns=['row_id', 'first_day_of_month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "739fa753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch:  tensor([[-0.2786, -0.0349, -0.1089, -0.1943, -0.5048, -0.4250, -0.8094, -0.8725,\n",
      "         -0.9225, -0.9420, -0.8682, -0.6677, -0.6880, -0.6749, -0.6950, -0.6894,\n",
      "         -0.3305, -0.0869, -0.1474, -0.5155, -0.3865, -0.3252, -0.2855, -0.2475,\n",
      "         -0.2153, -0.1985,  1.3195,  0.0908],\n",
      "        [-0.8701,  0.2023,  0.1398,  0.0888,  0.1869,  0.1967, -0.1107, -0.1263,\n",
      "          0.0619,  0.1490,  0.2299, -0.5273, -0.5303, -0.5180, -0.5367, -0.4973,\n",
      "          0.2779,  0.3377,  0.3854,  0.0903,  0.2330, -0.0888, -0.1862, -0.1949,\n",
      "         -0.2027, -0.2302, -1.7075,  0.3857],\n",
      "        [-0.6141, -1.0563, -0.7793, -0.6245, -0.5291, -0.2093, -0.9527, -0.8902,\n",
      "         -0.8874, -1.2364, -1.1771, -0.3168, -0.3377, -0.4135, -0.4136, -0.5497,\n",
      "         -1.4458, -1.0424, -0.0409, -0.1116, -0.2833,  0.0369, -0.1021, -0.0939,\n",
      "          0.0048, -0.2111,  0.3105, -0.4991]])\n",
      "y_pred:  tensor([[-0.0948],\n",
      "        [ 0.3198],\n",
      "        [ 0.0728]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.0740, 2.6730, 1.3823])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\dh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.4745,  1.1206,  1.4157,  1.5946,  1.6312,  1.5288,  1.8599,  1.9701,\n",
      "          2.0836,  1.7250,  1.6369, -0.2817, -0.3201, -0.0301, -0.1147,  0.0265,\n",
      "         -0.6347, -0.9362,  1.1313,  3.7253,  4.4664,  1.7346,  1.7182,  1.6172,\n",
      "          2.4249,  2.4806, -1.7075,  0.9756],\n",
      "        [-0.5479,  0.2746,  0.3344,  0.3265,  0.3447,  0.3109, -0.1823, -0.2329,\n",
      "         -0.2193, -0.2320, -0.1819, -0.2993, -0.3377, -0.3612, -0.3960, -0.3925,\n",
      "         -0.1277, -0.1931, -0.3605, -0.4145, -0.5930, -0.5415, -0.4932, -0.4393,\n",
      "         -0.4802, -0.5549, -1.7075,  1.2705],\n",
      "        [ 0.3780,  0.1714,  0.1614,  0.3152,  0.4661,  0.4124, -0.3973, -0.3750,\n",
      "         -0.3776, -0.3705, -0.3706, -0.3344, -0.3201, -0.2741, -0.2202, -0.2005,\n",
      "         -0.3305, -0.2992, -0.1474, -0.1116,  0.1297,  0.0298,  0.0137,  0.0116,\n",
      "          0.0209,  0.0254,  1.3195,  0.9756]])\n",
      "y_pred:  tensor([[0.2299],\n",
      "        [0.2373],\n",
      "        [0.0843]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([7.8485, 2.6189, 3.2869])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.9668, -0.8087, -0.6387, -0.7038, -1.0146, -0.6533, -0.3794, -0.1441,\n",
      "         -0.1139, -0.1800, -0.4393, -0.3344, -0.4252, -0.5006, -0.5367, -0.5497,\n",
      "         -1.3444, -0.6177, -0.3605,  0.6962,  0.5428, -0.4383, -0.5164, -0.5049,\n",
      "         -0.3551, -0.3713,  0.3105, -1.0890],\n",
      "        [ 0.7721,  0.3468,  0.3669,  0.4850,  0.3569,  0.4250,  0.5701,  0.6199,\n",
      "          0.6421,  0.5474,  0.5387,  0.1218,  0.1353,  0.1442,  0.1491,  0.1837,\n",
      "          0.5821,  0.4439,  0.5985,  0.3933,  0.3362, -0.1055, -0.0531, -0.0477,\n",
      "         -0.0669,  0.0070,  0.3105, -0.2042],\n",
      "        [-1.1351,  0.5325,  0.5399,  0.6662,  0.9758,  0.8691,  0.2118,  0.2290,\n",
      "          0.2202,  0.6859,  0.8819, -0.1764, -0.1975, -0.1521, -0.1323, -0.0084,\n",
      "         -0.8375, -0.7239, -0.8933, -0.9194, -0.5930, -0.5123, -0.3006, -0.1205,\n",
      "         -0.1483,  0.3813,  0.3105,  0.0908]])\n",
      "y_pred:  tensor([[0.1173],\n",
      "        [0.1373],\n",
      "        [0.2020]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.2273, 5.4787, 3.8911])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0203,  0.3984,  0.4642,  1.0058,  1.0608,  1.3639,  0.8388,  0.9752,\n",
      "          2.1188,  1.2228,  1.3795, -0.5624, -0.5829, -0.0650, -0.4136, -0.3402,\n",
      "         -0.4319, -0.8300, -0.7867, -0.8184, -0.2833, -0.2541, -0.5052, -0.1585,\n",
      "         -1.0275, -0.2500, -0.6985, -1.3840],\n",
      "        [-1.1320, -0.0762, -0.0116, -0.1037,  0.1627,  0.1967, -1.1318, -1.2455,\n",
      "         -1.2390, -1.1672, -1.1084,  0.3850,  0.3105,  0.3533,  0.3425,  0.4456,\n",
      "          0.4807,  0.9747,  0.5985,  0.6962,  0.5428, -0.6940, -0.5926, -0.6070,\n",
      "         -0.5599, -0.5987,  0.3105,  0.9756],\n",
      "        [-0.6184, -0.3754, -0.3792, -0.1716, -0.2742, -0.1205, -1.0781, -1.0857,\n",
      "         -0.8874, -0.9247, -1.0570, -0.6502, -0.6530, -0.7446, -0.7477, -0.7942,\n",
      "         -0.3305,  0.1254,  0.3854,  0.9991,  1.0590, -0.8379, -0.7865, -0.6065,\n",
      "         -0.6933, -0.7651,  0.3105,  0.3857]])\n",
      "y_pred:  tensor([[0.2544],\n",
      "        [0.2673],\n",
      "        [0.2604]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.6012, 2.2754, 0.8962])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0859,  0.2642,  0.0208, -0.1037, -0.4077, -0.6153,  0.0685, -0.3217,\n",
      "          0.0092, -0.0415, -0.3535, -0.6853, -0.6355, -0.6400, -0.6422, -0.5497,\n",
      "         -0.5333, -0.4054, -0.6802, -0.6165, -1.0061, -0.4561, -0.6512, -0.4026,\n",
      "         -0.5648, -0.6768,  1.3195, -0.4991],\n",
      "        [-0.6046, -0.2722, -0.5630, -0.6132, -0.9539, -0.5011, -0.6302, -0.5527,\n",
      "         -0.6237, -0.4744, -0.2334, -0.6326, -0.6179, -0.6052, -0.5895, -0.6195,\n",
      "         -1.1417, -1.2547, -0.6802, -1.3233, -0.9028, -0.1909,  0.0495, -0.2089,\n",
      "         -0.2775, -0.2939, -0.6985, -1.0890],\n",
      "        [ 0.5806,  0.5222,  0.5290,  0.4511,  0.3933,  0.1967, -0.1286, -0.0552,\n",
      "         -0.1139, -0.0934, -0.0961, -0.4572, -0.4428, -0.4658, -0.4664, -0.4449,\n",
      "         -0.3305, -0.4054, -0.3605, -0.3135, -0.4898,  0.3252,  0.3467,  0.3387,\n",
      "          0.4358,  0.4080, -1.7075,  1.5655]])\n",
      "y_pred:  tensor([[0.3189],\n",
      "        [0.3836],\n",
      "        [0.3250]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.3254, 1.4116, 2.8871])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.2820,  0.1095,  0.0641,  0.0888, -0.0922, -0.0571, -0.0032,  0.0336,\n",
      "         -0.1314, -0.2146, -0.1647, -0.4923, -0.4778, -0.4658, -0.4664, -0.5497,\n",
      "          0.1765,  0.2316,  0.5985,  0.2923, -0.1800, -0.3230, -0.1417, -0.1250,\n",
      "         -0.2374, -0.2075, -1.7075,  1.5655],\n",
      "        [-1.9334, -0.0556, -0.0548, -0.0924, -0.0558, -0.0824,  0.2476,  0.1935,\n",
      "          0.2026,  0.2703,  0.0926, -0.2642, -0.2501, -0.2915, -0.2905, -0.2703,\n",
      "          0.2779,  0.2316,  0.0657,  0.3933,  0.4395, -0.3019, -0.3972, -0.4172,\n",
      "         -0.3701, -0.4564,  1.3195, -0.2042],\n",
      "        [-1.6038,  0.5531,  0.6588,  0.5530,  0.7695,  0.8310,  0.0326,  0.1047,\n",
      "          0.0971,  0.0278,  0.0583,  0.1043,  0.1353,  0.1267,  0.1667,  0.1488,\n",
      "          0.5821,  0.6562,  0.7050,  0.2923,  0.3362, -0.1910, -0.0509,  0.0825,\n",
      "          0.1431,  0.2369,  1.3195, -0.4991]])\n",
      "y_pred:  tensor([[0.4017],\n",
      "        [0.3652],\n",
      "        [0.3495]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([10.7165,  3.9262,  6.6210])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.5488, -2.8309, -3.0500, -2.7983, -2.7986, -2.3534, -0.8452, -1.0857,\n",
      "         -1.0632, -0.8035, -0.6108, -0.7028, -0.7055, -0.6923, -0.6950, -0.6719,\n",
      "         -0.9389, -1.0424, -1.4261, -0.7174,  0.9558, -1.5491, -1.7383, -1.6325,\n",
      "         -1.5339, -1.3767,  1.3195,  0.6806],\n",
      "        [-0.8801,  0.7182,  0.7021,  0.6549,  0.6239,  0.7295,  0.4267,  0.3179,\n",
      "          0.2553,  0.2529,  0.1441, -0.5800, -0.4778, -0.4483, -0.4488, -0.4449,\n",
      "         -0.5333, -0.1931, -0.3605, -0.3135, -0.3865,  0.3723,  0.3427,  0.2248,\n",
      "          0.3339,  0.4721,  0.3105, -1.0890],\n",
      "        [-0.9446,  0.9245,  1.1994,  1.3908,  1.3035,  1.2116, -0.4331, -0.3217,\n",
      "          0.2026,  0.6859,  0.3672, -0.2642, -0.2851, -0.3089, -0.1323, -0.3227,\n",
      "         -1.4458, -1.4670, -1.4261, -1.3233, -1.3158, -0.4778, -0.0398,  0.0242,\n",
      "         -0.0382,  0.4191,  1.3195,  0.3857]])\n",
      "y_pred:  tensor([[1.0044],\n",
      "        [0.3784],\n",
      "        [0.5365]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([0.6843, 9.3806, 3.3123])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.9397,  0.4706,  0.5831,  0.7228,  0.7938,  0.9325,  1.1792,  1.1884,\n",
      "          1.1871,  0.9630,  0.9848, -0.2642, -0.2325, -0.1869, -0.2378, -0.2179,\n",
      "         -0.0263, -0.0869,  0.0657, -0.3135,  0.0265,  0.2129,  0.3185,  0.3401,\n",
      "          0.4585,  0.3920, -1.7075,  1.2705],\n",
      "        [-0.5470, -0.2000, -0.1522, -0.3754,  0.0292, -0.0697, -0.7019, -0.6948,\n",
      "         -0.4479, -0.5956, -0.3706, -0.7203, -0.7055, -0.6749, -0.6422, -0.5497,\n",
      "         -1.1417, -1.1485, -0.8933, -0.9194, -0.6963,  0.1743, -0.0688, -0.1336,\n",
      "         -0.1253, -0.1320, -0.6985, -0.7941],\n",
      "        [-0.2810,  0.3674,  0.4101,  0.3945,  0.2840,  0.3616, -0.1823, -0.1618,\n",
      "         -0.1139, -0.1627, -0.1133, -0.5273, -0.5128, -0.5180, -0.4840, -0.4798,\n",
      "         -0.6347, -0.5116, -0.4671, -0.5155, -0.6963, -0.2809, -0.2391, -0.1865,\n",
      "         -0.1069, -0.0779, -0.6985,  0.6806]])\n",
      "y_pred:  tensor([[0.6758],\n",
      "        [0.5294],\n",
      "        [0.4253]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([7.4261, 1.0934, 2.9069])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 6.4470e-01, -8.9126e-01, -3.6841e-01, -1.2635e-01,  3.2044e-01,\n",
      "          7.2954e-01,  1.2220e-01,  4.4222e-01,  5.7176e-01,  7.0322e-01,\n",
      "          3.6716e-01,  3.6308e+00,  3.7440e+00,  3.8734e+00,  4.0002e+00,\n",
      "          3.6411e+00,  1.2919e+00,  1.1870e+00,  4.9192e-01,  6.9617e-01,\n",
      "         -4.8979e-01, -2.2611e-02, -8.4176e-02, -8.5753e-02, -2.9652e-01,\n",
      "         -4.8137e-01, -6.9854e-01, -1.0890e+00],\n",
      "        [-8.7807e-01, -1.1748e-01, -2.2405e-02, -1.3131e-02,  4.2967e-01,\n",
      "          5.3923e-01, -3.7941e-01, -3.7502e-01, -4.3029e-01, -4.2247e-01,\n",
      "         -2.1621e-01, -5.2735e-01, -6.0042e-01, -6.7487e-01, -6.9497e-01,\n",
      "         -6.0208e-01, -5.3328e-01, -1.9308e-01, -9.9985e-01, -4.1451e-01,\n",
      "          7.4927e-01,  5.1456e-01,  2.4467e-01,  5.3465e-02,  5.9257e-02,\n",
      "          1.2746e-01, -6.9854e-01,  3.8570e-01],\n",
      "        [ 4.4686e-01, -2.8255e-01, -3.6841e-01, -3.1882e-01, -9.2194e-02,\n",
      "         -1.3318e-01, -3.2000e-03,  1.5833e-02, -2.1934e-01, -5.4369e-01,\n",
      "         -5.9369e-01, -3.8699e-01, -4.6028e-01, -4.6576e-01, -4.3120e-01,\n",
      "         -3.7508e-01, -8.3746e-01, -8.3005e-01, -4.6708e-01,  1.1001e+00,\n",
      "          1.5753e+00, -4.3611e-01, -4.1551e-01, -4.4685e-01, -2.7370e-01,\n",
      "         -3.2961e-01, -1.7075e+00,  1.5655e+00]])\n",
      "y_pred:  tensor([[1.2572],\n",
      "        [0.6107],\n",
      "        [0.6114]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.0518, 1.5289, 1.9422])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.9704, -1.1285, -1.0172, -0.9075, -0.7476, -0.4757, -0.3973, -0.4816,\n",
      "         -0.3600, -0.1800, -0.1819, -0.0536, -0.0749,  0.0222,  0.0260,  0.1138,\n",
      "          0.6835,  0.1254, -0.7867, -0.7174, -0.7996, -0.7741, -0.6457, -0.6539,\n",
      "         -0.6151, -0.4705, -0.6985,  0.3857],\n",
      "        [ 0.9676,  0.3777,  0.3669,  0.0774, -0.0679, -0.1712, -0.6123, -0.7481,\n",
      "         -0.8170, -0.6822, -0.7996, -0.4396, -0.3552, -0.4309, -0.3609, -0.3751,\n",
      "          0.4807,  0.7624,  1.0247,  0.6962,  0.3362, -1.1247, -1.1197, -1.2112,\n",
      "         -1.2496, -1.0841,  1.3195,  0.9756],\n",
      "        [ 0.4377, -0.1381, -0.2278,  0.1114, -0.1043, -0.1839, -0.3615, -0.6415,\n",
      "         -0.6764, -0.3532, -0.3706,  0.1745,  0.0302,  0.1790, -0.0092,  0.0265,\n",
      "         -0.4319, -0.7239, -0.9999, -1.2223, -1.2126, -0.8241, -1.0261, -1.1050,\n",
      "         -1.2216, -1.2444,  0.3105, -1.3840]])\n",
      "y_pred:  tensor([[0.8411],\n",
      "        [0.9794],\n",
      "        [1.0335]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.9980, 2.0743, 3.9054])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.3761,  0.5841,  0.4425,  0.5303,  0.6967,  0.7295,  0.5880,  0.5666,\n",
      "          0.5542,  0.5300,  0.5902,  1.0692,  1.0287,  1.0503,  1.1866,  1.2139,\n",
      "          1.1905,  1.2932,  1.2378,  0.7971,  0.8525,  1.9327,  1.8349,  1.8651,\n",
      "          1.7603,  1.7631,  1.3195, -1.6789],\n",
      "        [ 1.0376, -1.2627, -0.9199, -1.1793, -1.8156, -2.0489, -0.3973, -0.2507,\n",
      "         -0.2369,  0.5300,  0.4530, -0.7028, -0.7406, -0.6052, -0.5719, -0.6545,\n",
      "         -1.3444, -1.4670, -1.4261, -1.0203, -1.0061, -0.6162, -0.5697, -0.6294,\n",
      "         -0.2503, -0.2533, -1.7075,  0.6806],\n",
      "        [-1.6059,  1.2959,  1.2643,  1.1643,  1.1457,  1.0594,  1.6091,  1.7036,\n",
      "          1.7496,  1.7423,  1.6883,  0.2271,  0.1353,  0.0047,  0.1843,  0.2361,\n",
      "          0.4807,  0.1254,  0.3854, -0.0106,  0.1297,  0.8258,  0.8503,  0.8885,\n",
      "          0.9077,  1.0533, -0.6985, -0.7941]])\n",
      "y_pred:  tensor([[1.0544],\n",
      "        [1.1046],\n",
      "        [1.1175]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 6.0039,  1.8373, 12.6357])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1459, -0.6849, -0.8766, -0.6811, -0.8932, -1.3004, -0.8094, -0.9080,\n",
      "         -0.8522, -0.8035, -1.0398, -0.4747, -0.5303, -0.5006, -0.4136, -0.3576,\n",
      "         -0.7361, -0.0869, -0.4671, -0.5155, -0.4898, -0.6913, -0.4802, -0.3755,\n",
      "         -0.5499, -0.6098,  0.3105, -0.7941],\n",
      "        [-1.8728,  0.4293,  0.3236,  0.2020,  0.0534, -0.4504, -0.2361, -0.1618,\n",
      "         -0.0611, -0.0415, -0.0789,  5.7362,  6.1264,  6.4176,  6.5500,  7.0811,\n",
      "         -0.6347, -0.6177, -0.6802, -0.0106, -0.4898,  2.6977,  2.4779,  2.3956,\n",
      "          2.2129,  2.0894,  0.3105, -1.0890],\n",
      "        [ 0.1076,  1.5023,  1.4373,  1.5606,  1.4491,  1.4020,  0.5701,  0.6909,\n",
      "          0.7476,  0.9457,  0.8476,  0.5078,  0.5032,  0.4578,  0.3777,  0.2885,\n",
      "         -0.2291, -0.1931, -0.4671, -0.4145, -0.7996,  0.8689,  0.7964,  0.9388,\n",
      "          1.1182,  1.1223, -0.6985,  0.0908]])\n",
      "y_pred:  tensor([[1.2460],\n",
      "        [2.5376],\n",
      "        [1.0395]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 1.3788,  1.1662, 13.2403])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.0992,  0.6976,  0.5939,  0.6096,  0.5025,  0.4250, -0.1644, -0.2684,\n",
      "         -0.0963, -0.1627, -0.0789, -0.5449, -0.4077, -0.3612, -0.3433, -0.2878,\n",
      "          0.1765,  0.0192,  0.0657, -0.3135, -0.2833,  0.4862,  0.5143,  0.5935,\n",
      "          0.6109,  0.7002, -0.6985, -0.4991],\n",
      "        [-0.0248,  0.2746,  0.1939,  0.0661,  0.5632,  0.3362,  1.5195,  1.8102,\n",
      "          1.6090,  0.9803,  1.3280, -0.1589, -0.2501, -0.4309, -0.6422, -0.4449,\n",
      "          0.8863,  1.8240,  1.5575,  1.5039,  0.5428, -0.4482, -0.4963, -0.7262,\n",
      "         -0.6300, -0.4642, -1.7075,  0.3857],\n",
      "        [-0.2219,  0.5944,  0.6047,  0.6549,  0.5389,  0.4504,  0.1401,  0.2290,\n",
      "          0.4663,  0.3222,  0.4358, -0.4396, -0.4778, -0.4135, -0.3960, -0.4275,\n",
      "          0.6835,  0.6562,  1.1313,  0.9991,  0.7493,  0.4568,  0.4476,  0.5376,\n",
      "          0.3251,  0.3053,  0.3105,  1.2705]])\n",
      "y_pred:  tensor([[0.7571],\n",
      "        [1.2632],\n",
      "        [1.0569]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([5.8273, 3.8612, 3.2232])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.8727,  0.6150,  0.6047,  0.6549,  0.8302,  0.7803,  0.1939,  0.1757,\n",
      "          0.1498,  0.1144,  0.0412,  0.5604,  0.5733,  0.5624,  0.5360,  0.6028,\n",
      "          0.0751, -0.0869, -0.4671, -0.6165, -0.4898,  0.1264,  0.0751,  0.0959,\n",
      "          0.0640,  0.0461,  1.3195, -1.6789],\n",
      "        [-0.6060, -0.5198, -0.5630, -0.4434, -0.3349, -0.3362, -0.8452, -0.9080,\n",
      "         -0.8522, -0.8901, -0.9197, -0.4747, -0.4428, -0.4832, -0.4840, -0.4798,\n",
      "          0.1765,  0.8685,  0.7050,  1.2010,  1.1623, -1.1228, -0.9996, -0.9521,\n",
      "         -0.9825, -1.0048,  0.3105, -0.4991],\n",
      "        [ 0.7756,  0.3055,  0.2155,  0.2246,  0.3204,  0.3616, -0.4331, -0.3928,\n",
      "         -0.2897, -0.2666, -0.3363, -0.6853, -0.7055, -0.7097, -0.7126, -0.6894,\n",
      "         -0.0263,  0.0192, -0.0409, -0.1116, -0.1800, -0.2497, -0.2645, -0.2506,\n",
      "         -0.2485, -0.1518,  1.3195, -1.6789]])\n",
      "y_pred:  tensor([[0.9896],\n",
      "        [1.6294],\n",
      "        [1.1458]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.6533, 3.3232, 1.8348])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.5781, -0.4889, -0.1522, -0.4886, -0.5898, -0.7041, -1.2035, -1.0679,\n",
      "         -1.2214, -1.0286, -0.8854, -0.7905, -0.7931, -0.7794, -0.7829, -0.7069,\n",
      "         -1.3444, -1.1485, -0.9999, -0.9194, -0.7996, -0.4724, -0.5752, -0.7522,\n",
      "         -0.7464, -0.8561,  1.3195,  0.6806],\n",
      "        [-0.0829, -0.6127, -0.8225, -1.0208, -1.1602, -1.0466, -0.6481, -0.6060,\n",
      "         -0.4830, -0.4917, -0.4736, -0.6853, -0.6880, -0.6574, -0.6598, -0.6021,\n",
      "          0.1765,  0.8685,  1.0247,  1.9078,  2.2981, -0.8272, -0.8472, -0.7583,\n",
      "         -0.7067, -0.6229, -1.7075,  0.6806],\n",
      "        [-1.1353,  0.6976,  0.6480,  0.6096,  0.7816,  0.5265, -0.6660, -0.9968,\n",
      "         -0.7819, -1.0806, -1.2457,  0.3674,  0.2930,  0.1267, -0.1850, -0.1655,\n",
      "         -0.0263, -0.6177, -1.1064, -0.9194, -1.2126,  0.2526,  0.2803,  0.0781,\n",
      "         -0.2011, -0.3551, -0.6985, -0.2042]])\n",
      "y_pred:  tensor([[1.9042],\n",
      "        [1.7089],\n",
      "        [1.4071]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.4428, 2.0871, 1.3177])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.0534,  0.7285,  0.7237,  1.0171,  1.0850,  1.2243,  1.0538,  0.9219,\n",
      "          0.8355,  0.5127,  0.3500, -0.4923, -0.5128, -0.4832, -0.5543, -0.5846,\n",
      "          0.4807,  0.6562,  0.3854,  0.8981, -0.0768,  0.7767,  0.5974,  0.4796,\n",
      "          0.5506,  0.5202,  1.3195,  0.3857],\n",
      "        [-1.4754, -0.6333, -0.8658, -1.2132, -1.5971, -2.6833, -0.0390, -0.2151,\n",
      "         -0.1314,  0.2010,  0.2471, -0.5624, -0.6530, -0.6226, -0.6422, -0.6370,\n",
      "         -1.4458, -1.1485, -0.2540, -0.4145, -0.6963, -0.7169, -0.7224, -0.5308,\n",
      "          0.1190,  0.2732, -1.7075,  0.6806],\n",
      "        [ 0.1077,  1.1721,  1.0589,  1.0171,  1.0244,  0.9072, -0.3973, -0.4638,\n",
      "         -0.6940, -0.5956, -0.7138,  0.6833,  0.7134,  0.6669,  0.6063,  0.3932,\n",
      "         -0.0263,  0.2316,  0.1723, -0.3135, -0.4898,  2.0113,  1.8709,  1.9560,\n",
      "          1.6618,  1.5584,  1.3195, -0.4991]])\n",
      "y_pred:  tensor([[1.5681],\n",
      "        [1.9381],\n",
      "        [1.5372]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.1042, 4.6545, 3.0656])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.6764, -0.4992, -0.4333, -0.5453, -0.6990, -0.4250, -0.5227, -0.3395,\n",
      "         -0.7995, -0.4225, -0.1819, -0.4045, -0.4252, -0.4309, -0.3960, -0.3925,\n",
      "         -0.5333, -0.5116,  0.0657, -0.3135, -0.5930, -0.4085, -0.5339, -0.5083,\n",
      "         -0.3791, -0.2433, -1.7075,  1.5655],\n",
      "        [ 0.5777,  0.0785, -0.0548,  0.0095, -0.2985, -0.4504, -0.7735, -0.7481,\n",
      "         -0.5358, -0.5091, -0.5251, -0.5800, -0.5829, -0.5355, -0.5895, -0.5846,\n",
      "         -0.5333, -0.4054, -0.4671, -0.4145, -0.3865,  0.0076,  0.0242,  0.1292,\n",
      "          0.1016,  0.1114,  1.3195,  0.0908],\n",
      "        [ 0.4412,  0.3365,  0.3452,  0.3945,  0.4904,  0.4124, -0.1644, -0.1618,\n",
      "         -0.1666, -0.2320, -0.1647,  0.0165,  0.0477,  0.0222,  0.0612,  0.1313,\n",
      "          0.4807,  0.2316,  0.0657, -0.0106,  0.0265, -0.3016, -0.3164, -0.2787,\n",
      "         -0.3135, -0.3332, -0.6985,  0.9756]])\n",
      "y_pred:  tensor([[1.6950],\n",
      "        [1.4143],\n",
      "        [1.0329]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.2434, 1.2910, 2.0464])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0777, -0.0659, -0.0440, -0.0245, -0.0922, -0.3996, -0.8094, -0.9258,\n",
      "         -0.7467, -1.0113, -0.8854, -0.7905, -0.7931, -0.7794, -0.5719, -0.5322,\n",
      "          0.3793,  0.3377, -0.2540,  1.2010,  1.4721, -0.5199, -0.6310, -0.2407,\n",
      "         -0.5010, -0.6150, -0.6985, -0.2042],\n",
      "        [-0.2200,  0.1095,  0.1614,  0.1567,  0.2476,  0.1332,  0.1401,  0.1580,\n",
      "          0.2553,  0.1664,  0.1269, -0.5624, -0.5654, -0.5529, -0.5543, -0.5497,\n",
      "          0.1765,  0.2316, -0.3605, -0.4145, -0.3865,  0.5580,  0.5734,  0.5437,\n",
      "          0.6373,  0.5755,  1.3195,  0.6806],\n",
      "        [-1.6058,  1.8324,  1.7941,  1.7304,  1.6312,  1.5669,  2.0391,  2.0767,\n",
      "          2.0660,  2.0367,  2.0143,  4.4905,  4.4622,  4.4136,  4.3695,  4.3047,\n",
      "          0.8863,  0.9747,  0.9181,  0.7971,  0.8525,  2.4433,  2.4692,  2.5908,\n",
      "          2.6908,  2.7189,  0.3105, -1.6789]])\n",
      "y_pred:  tensor([[1.9240],\n",
      "        [1.4837],\n",
      "        [4.4380]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 2.7643,  2.6768, 16.8608])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.8111, -0.0143, -0.0332,  0.0435,  0.0170, -0.0571, -0.6840, -0.7659,\n",
      "         -0.7995, -0.5783, -0.5594, -0.5624, -0.6004, -0.5877, -0.5543, -0.5672,\n",
      "         -0.3305, -0.6177, -0.6802, -0.6165, -0.2833,  0.0167,  0.0358,  0.0079,\n",
      "          0.1842,  0.1148,  0.3105,  0.3857],\n",
      "        [-0.6180, -0.5508, -0.4441, -0.1603,  0.0656,  0.1713, -0.2719, -0.4461,\n",
      "         -0.3776, -0.1973, -0.3878,  0.0165,  0.0302,  0.0745, -0.0092, -0.1306,\n",
      "         -0.8375, -0.0869, -0.3605, -0.3135, -0.1800, -0.1432, -0.0102, -0.2723,\n",
      "         -0.5477, -0.3207, -0.6985, -1.3840],\n",
      "        [-1.6749, -1.7166, -1.4605, -1.3604, -1.3180, -0.7802, -1.0243, -1.0146,\n",
      "         -1.2038, -1.5655, -1.2800, -0.6853, -0.7230, -0.6400, -0.5191, -0.5497,\n",
      "          1.6974,  0.4439,  0.5985, -0.6165, -0.6963, -0.9550, -0.5538, -0.4994,\n",
      "         -0.3143, -0.1515,  0.3105, -1.6789]])\n",
      "y_pred:  tensor([[1.6628],\n",
      "        [1.5503],\n",
      "        [3.1399]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.1739, 2.6473, 0.3788])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.8128,  0.4603,  0.3777,  0.4058,  0.4661,  0.4885, -0.1286, -0.0375,\n",
      "         -0.0435, -0.1800, -0.1647, -0.4747, -0.4252, -0.5180, -0.4664, -0.4798,\n",
      "          0.5821,  0.1254, -0.0409, -0.3135, -0.2833, -0.1377, -0.0536, -0.0793,\n",
      "          0.0918,  0.0631, -0.6985, -0.7941],\n",
      "        [ 1.0984,  0.4603,  0.4642,  0.4171,  0.3326,  0.4377,  0.2834,  0.2823,\n",
      "          0.2202,  0.1490,  0.1784, -0.2993, -0.3201, -0.3263, -0.3081, -0.3052,\n",
      "          0.6835,  0.7624,  0.5985,  0.6962,  0.2330,  0.1071,  0.1854,  0.2235,\n",
      "          0.3591,  0.4079,  1.3195,  0.9756],\n",
      "        [ 0.3092, -1.5309, -1.6768, -1.6208, -1.3908, -0.8056, -0.7019, -1.1034,\n",
      "         -1.4148, -1.2884, -0.8854,  0.3499,  0.4506,  0.1442, -0.2202, -0.1306,\n",
      "         -0.5333,  0.2316,  0.8116,  1.5039, -0.3865, -0.8777, -0.9985, -1.2422,\n",
      "         -1.3359, -1.3401, -1.7075,  0.6806]])\n",
      "y_pred:  tensor([[1.4823],\n",
      "        [1.6210],\n",
      "        [2.9846]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.1257, 6.0804, 1.4013])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.8801,  0.7182,  0.7021,  0.6549,  0.6239,  0.7295,  0.4267,  0.3179,\n",
      "          0.2553,  0.2529,  0.1441, -0.5800, -0.4778, -0.4483, -0.4488, -0.4449,\n",
      "         -0.5333, -0.1931, -0.3605, -0.3135, -0.3865,  0.3723,  0.3427,  0.2248,\n",
      "          0.3339,  0.4721,  0.3105,  1.2705],\n",
      "        [ 0.7687,  1.6983,  1.6103,  1.5266,  1.4977,  1.4654,  1.7524,  1.7747,\n",
      "          1.7848,  1.8116,  1.8256,  0.7183,  0.7484,  0.8761,  0.8701,  0.8996,\n",
      "          1.0891,  1.0808,  0.9181,  0.9991,  0.9558,  2.4570,  2.5172,  2.5136,\n",
      "          2.6048,  2.6427, -0.6985,  0.3857],\n",
      "        [-1.9324, -0.7159, -0.7036, -0.4660, -0.5898, -0.6787, -0.5765, -0.7126,\n",
      "         -0.5006, -0.5956, -0.6795, -0.2817, -0.3902, -0.1869, -0.2905, -0.2878,\n",
      "          0.2779,  0.5500,  0.3854, -0.3135, -0.1800, -0.8207, -0.7762, -0.7797,\n",
      "         -0.8767, -0.9138,  0.3105, -1.3840]])\n",
      "y_pred:  tensor([[1.9712],\n",
      "        [3.9535],\n",
      "        [2.8150]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([9.9413, 8.2018, 2.2474])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.1563, -1.7888, -1.9363, -1.8359, -2.4952, -2.8228, -1.3468, -1.4765,\n",
      "         -1.4675, -1.7040, -1.8119, -0.5800, -0.5654, -0.5703,  0.1139,  0.4456,\n",
      "         -0.9389, -1.4670, -1.4261, -1.3233, -0.7996, -0.6976, -1.1418, -1.2159,\n",
      "         -1.0440, -1.2199,  1.3195, -1.0890],\n",
      "        [ 0.9709,  0.7491,  0.7777,  0.7794,  0.7209,  0.6661,  1.5912,  1.4726,\n",
      "          1.5562,  1.4306,  1.4481,  0.1569,  0.1353,  0.1616,  0.2019,  0.2012,\n",
      "          1.3933,  1.3993,  1.1313,  1.1001,  1.3688,  0.1764,  0.1695,  0.0895,\n",
      "         -0.0411, -0.1365,  1.3195, -1.3840],\n",
      "        [-0.0835, -0.0762, -0.0981,  0.0435, -0.7112, -0.9832, -1.0243, -0.9968,\n",
      "         -1.0280, -0.9420, -1.1942, -0.6853, -0.6705, -0.6923, -0.6950, -0.6545,\n",
      "         -1.1417, -1.1485, -0.9999, -0.8184, -0.4898, -0.1994, -0.2804, -0.5296,\n",
      "         -0.6779, -0.7731,  0.3105, -1.6789]])\n",
      "y_pred:  tensor([[4.6736],\n",
      "        [2.6598],\n",
      "        [2.8793]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.6697, 5.5288, 1.2694])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0849, -0.5302, -0.5090, -0.3641, -0.1529, -0.2347, -0.9168, -0.8725,\n",
      "         -0.6764, -0.7862, -0.6623, -0.5975, -0.6179, -0.6226, -0.6246, -0.6021,\n",
      "          0.4807,  0.0192, -0.7867, -1.0203, -1.1093, -1.1257, -1.1295, -1.0678,\n",
      "         -1.0628, -0.9695, -1.7075,  0.9756],\n",
      "        [ 0.5696, -1.5619, -1.3740, -1.2698, -0.8689, -0.5392, -1.0602, -0.9968,\n",
      "         -1.0456, -1.0632, -1.0913, -0.6853, -0.7230, -0.7446, -0.6950, -0.7069,\n",
      "         -0.9389, -0.6177, -0.2540, -0.5155, -0.5930, -1.0239, -1.0746, -1.0169,\n",
      "         -1.0229, -0.8879, -0.6985,  0.3857],\n",
      "        [-0.8818, -0.1897, -0.3252,  0.0095,  0.0656,  0.1586, -0.4152, -0.4105,\n",
      "         -0.3248, -0.1281,  0.0755, -0.6151, -0.6355, -0.6226, -0.7477, -0.7069,\n",
      "         -0.3305,  0.4439,  0.1723,  0.4942,  1.0590,  0.1753,  0.1867,  0.2139,\n",
      "          0.3031,  0.5028, -1.7075,  1.2705]])\n",
      "y_pred:  tensor([[3.5273],\n",
      "        [3.4734],\n",
      "        [2.1960]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.3511, 1.4600, 1.3855])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.2415,  0.4603,  0.5182,  0.5643,  0.5632,  0.6915,  0.1222,  0.0514,\n",
      "         -0.0260, -0.0241,  0.1441,  0.0341, -0.0399, -0.1695, -0.2026, -0.1655,\n",
      "         -0.1277, -0.6177, -0.5736, -0.4145,  0.0265,  1.0789,  0.9284,  0.9411,\n",
      "          0.6277,  0.6207,  0.3105,  0.0908],\n",
      "        [ 1.1080,  0.2849,  0.3236,  0.2246,  0.1020, -0.0063, -0.3794, -0.5171,\n",
      "         -0.4303, -0.3878, -0.4221,  0.0341,  0.0653,  0.0745,  0.0963,  0.0964,\n",
      "         -0.4319, -0.2992, -0.3605, -0.3135, -0.3865, -0.4031, -0.4135, -0.2742,\n",
      "         -0.2260, -0.2507,  0.3105, -1.0890],\n",
      "        [-0.0790, -0.6952, -0.2711, -0.2396, -0.1771, -0.8310, -1.2214, -1.0324,\n",
      "         -0.7467, -0.4917, -0.6966, -0.7730, -0.7230, -0.7620, -0.7477, -0.8116,\n",
      "         -0.1277, -0.0869, -0.0409, -0.3135, -0.9028, -0.7235, -0.7798, -0.9291,\n",
      "         -1.0581, -1.0516,  0.3105,  1.5655]])\n",
      "y_pred:  tensor([[1.8204],\n",
      "        [1.5847],\n",
      "        [3.2769]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.3843, 7.9147, 1.3688])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 2.3990e-01,  1.0277e+00,  1.0805e+00,  1.0398e+00,  1.0244e+00,\n",
      "          9.8328e-01,  1.2329e+00,  1.1706e+00,  1.2046e+00,  1.2055e+00,\n",
      "          1.2251e+00,  1.6549e-02,  1.2701e-02, -1.2679e-02, -6.1914e-02,\n",
      "          9.0790e-03,  7.5101e-02,  1.2540e-01,  6.5701e-02,  4.9423e-01,\n",
      "          6.4601e-01,  9.5692e-01,  8.8316e-01,  9.5746e-01,  1.1844e+00,\n",
      "          1.1576e+00, -6.9854e-01, -1.6789e+00],\n",
      "        [ 9.6616e-01, -1.0717e-01, -7.7948e-04,  1.3405e-01,  2.3549e-01,\n",
      "          3.3624e-01, -1.1069e-01, -7.2996e-02, -2.5958e-02,  9.7082e-02,\n",
      "          1.0979e-01, -3.5190e-01, -3.2013e-01, -2.9150e-01, -3.0810e-01,\n",
      "         -2.5285e-01,  7.5101e-02,  1.2540e-01,  1.7226e-01,  9.0342e-02,\n",
      "          2.6481e-02, -3.2097e-01, -2.7004e-01, -1.8569e-01, -9.8720e-02,\n",
      "         -9.4089e-02,  3.1046e-01, -1.0890e+00],\n",
      "        [ 7.7241e-01,  1.0949e-01,  2.1548e-01,  2.8123e-01,  2.8403e-01,\n",
      "          3.3624e-01, -3.9029e-02,  5.1365e-02,  6.1942e-02,  1.3172e-01,\n",
      "          4.1157e-02, -5.7998e-01, -5.4786e-01, -5.7032e-01, -5.7188e-01,\n",
      "         -5.6716e-01,  1.7650e-01,  1.2540e-01,  3.8537e-01,  2.9228e-01,\n",
      "          2.3299e-01, -1.9631e-01, -2.0034e-01, -2.3231e-01, -3.3900e-01,\n",
      "         -3.3167e-01,  1.3195e+00,  9.7559e-01]])\n",
      "y_pred:  tensor([[2.6857],\n",
      "        [1.3993],\n",
      "        [2.0672]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([6.8632, 2.7947, 3.4466])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.1035, -1.0460, -1.1361, -1.2019, -1.8156, -1.4019, -1.6155, -1.4587,\n",
      "         -1.1686, -1.0113, -0.7653, -0.7028, -0.6705, -0.6400, -0.6246, -0.6195,\n",
      "          0.3793,  0.9747, -0.2540,  0.2923,  0.9558, -1.2057, -1.0885, -1.2900,\n",
      "         -1.3089, -1.0538,  0.3105, -1.6789],\n",
      "        [-1.8614, -0.3238, -0.2819,  0.1454, -0.0194,  0.0825, -1.2035, -1.1567,\n",
      "         -1.1159, -1.0979, -1.3315, -0.5975, -0.6004, -0.5703, -0.5719, -0.5322,\n",
      "          0.5821,  0.0192, -0.1474, -0.4145, -0.1800,  0.8961,  0.8290,  0.5225,\n",
      "          0.5947,  0.6694, -0.6985, -1.3840],\n",
      "        [-1.6743, -1.0666, -0.9847, -0.9755, -0.7840, -0.7929, -1.2572, -1.2455,\n",
      "         -1.2390, -1.2884, -1.1427, -0.6853, -0.6880, -0.6923, -0.7126, -0.7942,\n",
      "         -0.8375, -1.0424, -0.6802, -0.9194,  0.1297, -1.3362, -1.2908, -1.1471,\n",
      "         -1.1686, -1.1873, -0.6985, -1.6789]])\n",
      "y_pred:  tensor([[3.9561],\n",
      "        [2.8221],\n",
      "        [4.4136]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.9329, 0.5185, 0.8429])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0234,  0.5222,  0.4317,  0.2473,  0.7452,  0.9706,  0.1401,  0.1757,\n",
      "          0.2026,  0.4781,  0.0240, -0.5449, -0.6530, -0.5355, -0.5719, -0.5497,\n",
      "         -0.3305, -0.5116, -0.3605, -0.5155, -0.0768,  0.7505,  0.6004,  0.3595,\n",
      "         -0.2296, -0.0369,  0.3105,  0.3857],\n",
      "        [-0.2848, -0.3032, -0.3360, -0.3528, -0.4199, -0.4630, -0.6123, -0.6415,\n",
      "         -0.6061, -0.7169, -0.7310, -0.5624, -0.5654, -0.5529, -0.5895, -0.5846,\n",
      "         -0.0263, -0.0869, -0.1474,  0.1913,  0.0265, -0.3484, -0.3859, -0.3674,\n",
      "         -0.3758, -0.4078, -0.6985, -0.7941],\n",
      "        [ 0.6403, -0.5508, -0.4009, -0.4094,  0.3933,  0.4631,  0.4447,  0.3534,\n",
      "          0.2729,  0.2356,  0.1098,  0.4903,  0.4857,  0.6844,  0.9228,  0.8298,\n",
      "          4.0296,  3.9472,  6.1394,  7.3603,  6.2218,  0.9948,  0.6615,  0.3018,\n",
      "          0.4572,  0.2189,  1.3195, -1.0890]])\n",
      "y_pred:  tensor([[2.1708],\n",
      "        [2.2015],\n",
      "        [5.1187]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.6319, 2.2532, 3.0442])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.1084, -1.0047, -0.7144, -0.9868, -0.8082, -0.2093, -0.7377, -0.8547,\n",
      "         -0.7292, -0.4571, -0.1991, -0.3519, -0.4778, -0.4483, -0.5367, -0.4100,\n",
      "         -0.6347, -0.1931, -0.0409,  0.0903, -0.3865, -0.4322, -0.6819, -0.5423,\n",
      "         -0.3761, -0.4377,  0.3105,  0.9756],\n",
      "        [-0.2882, -0.8397, -0.7252, -0.4320, -0.1771, -0.1459, -1.1497, -1.1212,\n",
      "         -0.9753, -1.0632, -0.9025, -0.6326, -0.6004, -0.6400, -0.6598, -0.6545,\n",
      "         -0.7361, -0.6177, -0.6802, -0.6165, -0.9028, -0.7477, -0.7915, -0.7904,\n",
      "         -0.6396, -0.5967,  0.3105, -0.7941],\n",
      "        [ 0.9000,  1.3269,  1.2211,  1.2096,  1.2549,  1.2624,  2.5407,  2.5919,\n",
      "          2.5055,  2.6429,  2.4604,  0.4376,  0.3806,  0.4230,  0.3425,  0.2885,\n",
      "         -0.1277,  0.1254,  0.3854,  0.7971,  0.9558,  1.9569,  1.8729,  1.8306,\n",
      "          1.9970,  2.0718, -1.7075,  1.2705]])\n",
      "y_pred:  tensor([[2.2664],\n",
      "        [3.2013],\n",
      "        [4.3617]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.5621, 2.1945, 8.3286])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.2118,  1.0071,  0.9075,  0.9153,  1.0729,  1.1609,  0.9821,  0.9930,\n",
      "          0.9585,  1.0150,  1.0020, -0.2466, -0.2325, -0.2566, -0.2378, -0.2878,\n",
      "          0.8863,  1.1870,  0.8116,  0.3933,  0.6460,  0.3205,  0.2869,  0.4112,\n",
      "          0.3399,  0.2251, -0.6985, -0.4991],\n",
      "        [-0.0905, -0.0453,  0.0857, -0.0471,  0.0777, -0.2981,  0.6238,  0.4422,\n",
      "          0.4311,  0.3915, -0.0103, -0.7203, -0.6880, -0.6749, -0.7477, -0.7592,\n",
      "          0.3793,  0.3377, -0.0409, -0.5155,  0.1297, -0.3432, -0.2350, -0.2300,\n",
      "         -0.2335, -0.2827,  0.3105,  0.3857],\n",
      "        [ 1.0993, -0.0453, -0.2170,  0.1227, -0.1286, -0.0317, -0.8631, -0.6770,\n",
      "         -0.8346, -0.8381, -0.8854, -0.3870, -0.5479, -0.5355, -0.5895, -0.5846,\n",
      "         -0.1277, -0.2992, -0.8933, -1.0203, -1.0061, -0.4589, -0.4336, -0.1095,\n",
      "         -0.1166, -0.3583,  0.3105,  0.9756]])\n",
      "y_pred:  tensor([[2.7142],\n",
      "        [2.0794],\n",
      "        [2.7670]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.8818, 5.4989, 1.3894])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.8716,  0.5634,  0.4534,  0.3605,  0.3569,  0.3616, -0.3077, -0.1796,\n",
      "         -0.1842, -0.1454, -0.1133, -0.4923, -0.4252, -0.3961, -0.4664, -0.5148,\n",
      "         -0.7361, -0.8300, -0.5736, -0.5155, -0.6963, -0.2543, -0.2620, -0.3310,\n",
      "         -0.3126, -0.2866,  1.3195, -0.4991],\n",
      "        [-0.7484, -0.1484, -0.0873, -0.1943, -0.1043, -0.1459, -0.3794, -0.1441,\n",
      "         -0.0963, -0.3186, -0.3020, -0.4396, -0.4428, -0.3786, -0.3784, -0.5322,\n",
      "         -0.8375, -1.0424, -0.6802,  0.9991,  0.9558,  0.1027,  0.0896, -0.0244,\n",
      "          0.0965, -0.0070,  0.3105,  1.5655],\n",
      "        [ 1.0352, -0.6230, -0.3360, -0.5113, -0.3228, -0.2981,  0.6059,  0.2823,\n",
      "          0.0092, -0.0241, -0.4393, -0.5975, -0.6179, -0.6052, -0.7301, -0.8116,\n",
      "         -1.1417, -1.1485, -1.1064, -0.8184, -1.1093, -0.5397, -0.5204, -0.7095,\n",
      "         -0.7060, -0.8759,  1.3195,  0.3857]])\n",
      "y_pred:  tensor([[2.5219],\n",
      "        [2.2553],\n",
      "        [2.7160]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([5.0224, 2.6754, 5.3538])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.9688, -0.4889, -0.2603, -0.2282, -0.3835, -0.2981,  0.2297,  0.2290,\n",
      "          0.3081,  0.2010,  0.0755, -0.0887, -0.0924, -0.0998, -0.0092, -0.2354,\n",
      "          0.1765,  0.0192, -0.4671, -0.3135, -0.6963, -0.8049, -0.7759, -0.7872,\n",
      "         -0.9536, -0.8849,  0.3105, -1.0890],\n",
      "        [-0.0777, -0.0659, -0.0440, -0.0245, -0.0922, -0.3996, -0.8094, -0.9258,\n",
      "         -0.7467, -1.0113, -0.8854, -0.7905, -0.7931, -0.7794, -0.5719, -0.5322,\n",
      "          0.3793,  0.3377, -0.2540,  1.2010,  1.4721, -0.5199, -0.6310, -0.2407,\n",
      "         -0.5010, -0.6150,  0.3105, -0.4991],\n",
      "        [ 0.7020,  1.0174,  0.9183,  0.8586,  0.8787,  0.8818,  0.2118,  0.1935,\n",
      "          0.2202,  0.1317,  0.3157, -0.0185,  0.0302, -0.0301,  0.0436,  0.0091,\n",
      "          0.7849,  0.2316, -0.5736, -0.4145, -0.3865,  0.0047,  0.0717,  0.0979,\n",
      "          0.1655,  0.2311,  1.3195, -1.3840]])\n",
      "y_pred:  tensor([[1.8813],\n",
      "        [2.6465],\n",
      "        [2.2491]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.6603, 2.0356, 6.3174])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0899, -1.0047, -0.6712, -0.4660, -0.4320, -0.5011, -1.2393, -1.0501,\n",
      "         -1.3093, -1.2364, -1.2800, -0.7203, -0.7055, -0.6574, -0.6422, -0.6545,\n",
      "         -1.3444, -1.3608, -1.3195, -1.2223, -1.1093, -1.1170, -0.9917, -0.9344,\n",
      "         -0.9079, -0.8193,  0.3105,  0.0908],\n",
      "        [-0.3535,  1.6158,  1.5346,  1.4474,  1.3399,  1.2751,  1.5912,  1.6148,\n",
      "          1.6617,  1.6384,  1.6712,  0.7534,  0.8010,  0.8238,  0.8701,  0.9520,\n",
      "          0.8863,  1.0808,  1.0247,  1.2010,  1.0590,  2.4608,  2.4879,  2.5383,\n",
      "          2.5860,  2.5711,  0.3105, -0.2042],\n",
      "        [-0.6156, -1.5825, -2.2715, -2.2322, -2.3860, -1.8840, -1.4722, -1.4054,\n",
      "         -1.4851, -1.3403, -1.2800, -0.5449, -0.7055, -0.6400, -0.5895, -0.5497,\n",
      "         -1.4458,  1.2932,  1.0247,  0.0903, -0.3865, -1.4191, -1.4968, -1.5032,\n",
      "         -1.4993, -1.4947,  0.3105,  0.3857]])\n",
      "y_pred:  tensor([[3.3163],\n",
      "        [3.5071],\n",
      "        [3.9255]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.8318, 6.4892, 0.4578])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.2871,  0.5738,  0.5074,  0.4624,  0.6603,  0.5265,  0.6596,  0.7442,\n",
      "          0.6772,  0.8071,  0.7961, -0.4747, -0.5128, -0.5180, -0.5191, -0.5322,\n",
      "         -0.6347, -0.7239, -0.5736, -0.7174, -0.6963,  0.1372,  0.1173,  0.1595,\n",
      "          0.3681,  0.3381,  1.3195, -0.2042],\n",
      "        [-0.2126,  0.5944,  0.8318,  0.7001,  0.3447,  0.3870,  0.1759,  0.1580,\n",
      "          0.2553,  0.3222,  0.5731, -0.5624, -0.4778, -0.5006, -0.5191, -0.4973,\n",
      "         -0.4319, -0.5116, -0.4671, -0.7174, -0.3865,  0.9296,  0.9889,  0.8271,\n",
      "          0.8785,  0.7949,  1.3195,  0.6806],\n",
      "        [-0.0875, -0.1278, -0.4225, -0.4660, -0.6141, -0.2854,  1.2150,  1.3127,\n",
      "          1.2749,  1.4133,  1.4138, -0.3168, -0.3026, -0.2566, -0.3081, -0.3751,\n",
      "          1.1905,  1.3993,  1.5575,  1.8068,  0.8525,  0.3389,  0.4373,  0.4632,\n",
      "          0.4194,  0.4158,  0.3105, -0.7941]])\n",
      "y_pred:  tensor([[2.5210],\n",
      "        [2.6836],\n",
      "        [1.9907]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([5.8857, 2.7717, 4.8488])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1352, -0.3857, -0.8334, -1.0547, -1.1966, -1.2370,  0.1939,  0.1402,\n",
      "          0.2026,  0.2183,  0.2471, -0.0712, -0.0924, -0.2392, -0.2378, -0.2354,\n",
      "          0.6835,  1.1870,  1.0247,  0.8981,  0.2330, -0.7505, -0.7461, -0.7798,\n",
      "         -0.6099, -0.6152,  0.3105,  1.2705],\n",
      "        [ 0.3733,  0.6253,  0.6372,  0.6549,  0.7088,  0.7169,  0.8030,  0.8508,\n",
      "          0.9058,  0.8764,  0.8991,  0.3674,  0.4156,  0.4230,  0.4305,  0.4282,\n",
      "          0.1765,  0.3377,  0.3854,  0.4942,  0.5428,  0.3229,  0.2974,  0.3260,\n",
      "          0.3019,  0.2782, -0.6985,  0.3857],\n",
      "        [ 1.1088,  0.1817,  0.1722, -0.0018, -0.0072, -0.0571, -0.7735, -0.6770,\n",
      "         -0.5885, -0.6303, -0.4907, -0.5624, -0.5479, -0.5355, -0.5719, -0.5497,\n",
      "         -1.0403, -1.0424, -0.8933, -0.8184, -0.5930,  0.5670,  0.6258,  0.5496,\n",
      "          0.5075,  0.3558,  0.3105, -1.6789]])\n",
      "y_pred:  tensor([[1.9271],\n",
      "        [1.6100],\n",
      "        [2.2845]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.8662, 5.8841, 1.9632])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.6104, -0.5714, -0.5955, -0.6698, -0.5048, -0.5392, -1.3468, -1.3344,\n",
      "         -1.4499, -1.6867, -1.7261, -0.7379, -0.7581, -0.7620, -0.7301, -0.7418,\n",
      "         -0.4319,  0.0192, -0.0409,  1.2010,  0.7493, -1.4829, -1.5888, -1.6652,\n",
      "         -1.4932, -1.4795, -0.6985, -1.6789],\n",
      "        [-0.0835, -0.0762, -0.0981,  0.0435, -0.7112, -0.9832, -1.0243, -0.9968,\n",
      "         -1.0280, -0.9420, -1.1942, -0.6853, -0.6705, -0.6923, -0.6950, -0.6545,\n",
      "         -1.1417, -1.1485, -0.9999, -0.8184, -0.4898, -0.1994, -0.2804, -0.5296,\n",
      "         -0.6779, -0.7731,  0.3105,  0.0908],\n",
      "        [-1.6714, -1.2730, -1.6768, -2.4586, -3.5875, -3.7109, -0.9348, -0.7303,\n",
      "         -0.9753, -0.8035, -0.4907, -0.4396, -0.4953, -0.6400, -0.7126, -0.6545,\n",
      "         -0.5333,  0.3377,  0.4919,  0.5952, -0.0768, -0.8096, -0.8317, -0.7491,\n",
      "         -0.8350, -0.8331,  1.3195, -0.4991]])\n",
      "y_pred:  tensor([[3.3909],\n",
      "        [2.5921],\n",
      "        [2.9398]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([0.8839, 1.3472, 1.4698])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1446, -1.7992, -1.6443, -1.3604, -1.1117, -0.6914, -0.7914, -0.8014,\n",
      "         -0.8522, -1.1152, -1.0570,  0.0692, -0.0399,  0.0745,  0.1491,  0.2535,\n",
      "         -0.6347, -0.0869, -0.4671, -0.2126,  0.0265, -1.2672, -1.3637, -1.3937,\n",
      "         -1.2354, -1.3839,  1.3195, -1.3840],\n",
      "        [-1.1408, -2.2944, -3.0824, -3.1719, -3.3690, -3.7870, -1.6155, -1.4410,\n",
      "         -1.4675, -1.5655, -1.2457,  0.5604,  0.4331,  0.2313,  0.3074,  0.2535,\n",
      "         -0.9389, -0.8300, -0.9999, -0.9194, -1.3158, -1.1766, -1.2534, -0.9876,\n",
      "         -0.7233, -0.8439,  0.3105, -1.0890],\n",
      "        [-0.2812, -0.3238, -0.3360, -0.2282, -0.0922, -0.1205, -0.8989, -0.9080,\n",
      "         -0.9401, -0.7688, -0.9025, -0.5975, -0.5829, -0.6052, -0.5895, -0.6021,\n",
      "         -0.5333, -0.0869, -0.4671, -0.2126,  0.1297, -0.3895, -0.3362, -0.2856,\n",
      "         -0.1812, -0.2224,  1.3195,  0.0908]])\n",
      "y_pred:  tensor([[2.5897],\n",
      "        [3.2604],\n",
      "        [2.2374]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.5840, 0.0645, 2.0904])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.7716,  0.0166,  0.0857,  0.0548,  0.1748,  0.1713, -0.6123, -0.4816,\n",
      "         -0.4655, -0.4744, -0.5422, -0.5975, -0.5654, -0.5703, -0.5719, -0.6021,\n",
      "          0.0751,  0.0192, -0.1474, -0.6165, -0.4898, -0.2285, -0.2196, -0.1284,\n",
      "         -0.0988, -0.0774, -0.6985,  0.3857],\n",
      "        [-0.6168,  0.3881,  0.4642,  0.7341,  0.5510,  0.1459,  0.4088,  0.3889,\n",
      "          0.2026,  0.4608,  0.4186,  0.1569,  0.0653, -0.1521, -0.1850, -0.2528,\n",
      "         -0.6347, -0.8300, -0.6802, -0.8184, -0.6963, -0.7993, -0.8317, -0.7916,\n",
      "         -0.9017, -0.8836, -0.6985,  0.9756],\n",
      "        [-0.2161,  1.1825,  1.1454,  1.0511,  0.9515,  0.7422,  1.3762,  1.3660,\n",
      "          1.4156,  1.4306,  1.4310, -0.0361, -0.0399, -0.0475, -0.0971, -0.0608,\n",
      "          0.6835,  0.6562,  0.7050,  0.8981,  0.8525,  0.9768,  0.9808,  0.9804,\n",
      "          0.9651,  1.0340,  1.3195, -0.4991]])\n",
      "y_pred:  tensor([[1.9442],\n",
      "        [2.3288],\n",
      "        [2.7211]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.5906, 4.4698, 3.4338])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.1011, -0.4167, -0.3252, -0.4660, -0.9296, -1.0340, -0.2898, -0.3040,\n",
      "         -0.4655, -0.3878, -0.3706, -0.3344, -0.3552, -0.3089, -0.3433, -0.3052,\n",
      "         -0.4319, -0.5116, -0.3605, -0.6165, -0.7996, -0.2196, -0.1873, -0.1349,\n",
      "         -0.4963, -0.3907,  1.3195, -0.7941],\n",
      "        [-1.6045,  1.5539,  1.4589,  1.4247,  1.2914,  1.2878,  1.3225,  1.3127,\n",
      "          1.3453,  1.3267,  1.3280,  0.9991,  0.9762,  0.9283,  0.8349,  0.8647,\n",
      "          0.1765,  0.3377,  0.3854,  0.9991,  0.9558,  1.3257,  1.3952,  1.4119,\n",
      "          1.5644,  1.5618,  0.3105, -1.3840],\n",
      "        [ 0.6454, -0.3238, -0.4441, -0.2396, -0.0072,  0.1713,  0.3193, -0.0730,\n",
      "         -0.0963, -0.5437, -0.5594, -0.3694, -0.3727, -0.4483, -0.4312, -0.4973,\n",
      "         -0.3305, -0.4054, -0.0409, -0.1116, -0.4898,  0.1632,  0.0663, -0.0158,\n",
      "         -0.1675, -0.1614,  0.3105, -1.0890]])\n",
      "y_pred:  tensor([[1.8083],\n",
      "        [2.6994],\n",
      "        [1.4830]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 2.5726, 11.0070,  1.4753])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.6805,  0.7388,  0.6047,  0.6662,  1.1943,  0.8564,  1.8420,  1.8457,\n",
      "          1.2574,  0.8071,  0.6932,  0.4727,  0.6609,  1.0503,  0.9228,  0.9695,\n",
      "          1.4946,  2.8856,  3.2624,  5.8457,  5.7055, -0.2072, -0.0257,  0.0433,\n",
      "         -0.0883, -0.0629,  1.3195, -0.4991],\n",
      "        [ 1.0359,  0.8936,  1.0805,  1.4813,  0.8909,  0.7549,  1.8420,  1.3660,\n",
      "          1.3277,  1.1015,  0.7790, -0.4747, -0.4252, -0.5529, -0.6070, -0.5846,\n",
      "         -0.2291, -0.5116, -0.6802, -0.9194, -0.2833,  0.4726,  0.4210,  0.4342,\n",
      "          0.4144,  0.3858,  1.3195,  0.3857],\n",
      "        [ 0.0496,  0.0682,  0.3993,  0.1001, -0.0679, -0.1459,  1.0358,  1.0818,\n",
      "          0.9409,  0.8071,  1.0192, -0.6151, -0.5829, -0.5529, -0.5719, -0.5672,\n",
      "         -0.5333, -0.7239, -1.1064, -1.3233, -1.3158,  0.4394,  0.0234, -0.1178,\n",
      "         -0.3283, -0.3333,  1.3195,  0.0908]])\n",
      "y_pred:  tensor([[3.6299],\n",
      "        [3.2268],\n",
      "        [2.6789]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.3095, 3.8503, 2.1478])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.6681, -0.2207, -0.1522, -0.0584,  0.0777,  0.0698,  0.1401,  0.1047,\n",
      "          0.1498,  0.3222,  0.1613,  0.0867,  0.0828,  0.1093,  0.1139,  0.1313,\n",
      "         -0.5333, -0.5116, -0.2540, -0.4145, -0.3865, -0.6928, -0.7078, -0.7078,\n",
      "         -0.6174, -0.7041, -0.6985, -1.0890],\n",
      "        [-1.4716,  1.2134,  1.0589,  1.1870,  1.1457,  1.1482,  2.7377,  2.5741,\n",
      "          2.4352,  2.6775,  2.3232, -0.4396, -0.4778, -0.5355, -0.4840, -0.4973,\n",
      "          0.7849,  2.5671,  2.5165,  3.1195,  0.5428,  0.8808,  0.7765,  0.9111,\n",
      "          0.9459,  0.5776,  1.3195, -0.2042],\n",
      "        [-0.0230,  0.2746,  0.4534,  0.3605,  0.5996,  0.4631,  1.4837,  1.4371,\n",
      "          1.3628,  0.9630,  1.0363, -0.5098, -0.5829, -0.6400, -0.4312, -0.4798,\n",
      "         -0.2291,  0.1254, -0.1474, -0.1116, -0.3865, -0.2023, -0.0932, -0.2086,\n",
      "         -0.5072, -0.3423,  0.3105, -0.4991]])\n",
      "y_pred:  tensor([[1.9232],\n",
      "        [3.9967],\n",
      "        [2.2471]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 2.6964, 13.8096,  2.7831])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.3783,  0.6253,  0.5939,  0.5416,  0.4782,  0.4124, -0.0749, -0.1618,\n",
      "         -0.1139, -0.0068,  0.0926,  0.8236,  0.8185,  0.8063,  0.8349,  0.8822,\n",
      "          0.1765,  0.3377,  0.2788,  0.1913,  0.5428,  0.3131,  0.3400,  0.2770,\n",
      "          0.3681,  0.3307,  1.3195, -1.3840],\n",
      "        [-1.6078,  0.4087,  0.4425,  0.4850,  0.6239,  0.6661, -0.5944, -0.5882,\n",
      "         -0.5709, -0.5610, -0.5594,  2.6658,  2.6754,  2.6361,  2.6462,  2.6109,\n",
      "         -0.3305, -0.2992, -0.2540, -0.3135, -0.3865,  0.0807,  0.0641, -0.0104,\n",
      "         -0.0131,  0.0365,  0.3105,  0.6806],\n",
      "        [ 0.9716, -2.4491, -2.5850, -2.7304, -2.3010, -2.1377, -0.9527, -0.9791,\n",
      "         -1.1159, -0.9940, -0.8339, -0.5098, -0.5479, -0.5180, -0.5191, -0.4798,\n",
      "          0.4807, -0.4054, -0.1474, -0.5155,  0.2330, -1.4309, -1.4065, -1.4820,\n",
      "         -1.3224, -1.1675, -0.6985,  0.3857]])\n",
      "y_pred:  tensor([[1.3606],\n",
      "        [1.9128],\n",
      "        [2.4582]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([4.4861, 3.4720, 1.4371])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.1027, -1.5722, -1.2118, -1.6774, -1.3908, -1.5795, -1.0781, -1.1922,\n",
      "         -1.4499, -1.2537, -1.2800, -0.5273, -0.5303, -0.2392, -0.3081, -0.3925,\n",
      "         -0.6347, -0.8300, -0.9999, -1.1213, -1.2126, -1.0393, -0.9673, -1.0997,\n",
      "         -1.0962, -1.1786,  1.3195, -0.2042],\n",
      "        [-0.1547,  0.9864,  1.1670,  1.2436,  1.3156,  1.1990,  0.3909,  0.4067,\n",
      "          0.4135,  0.2703,  0.3672, -0.2115, -0.1975, -0.1869, -0.1498, -0.1481,\n",
      "         -0.3305, -0.2992, -0.3605, -0.4145, -0.3865,  0.9769,  0.9912,  0.9549,\n",
      "          1.0208,  0.9788,  1.3195, -1.6789],\n",
      "        [-0.2885,  0.0476,  0.1506,  0.1567, -0.1043,  0.0318, -0.4869, -0.5171,\n",
      "         -0.5006, -0.5264, -0.7138, -0.5975, -0.5829, -0.6052, -0.6070, -0.5672,\n",
      "         -0.4319,  0.1254,  0.2788,  0.3933,  0.1297, -0.6710, -0.7022, -0.7148,\n",
      "         -0.8497, -0.8623,  0.3105, -1.0890]])\n",
      "y_pred:  tensor([[2.4382],\n",
      "        [2.7581],\n",
      "        [2.0942]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.1280, 4.1581, 2.2868])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1450, -0.9532, -1.6659, -1.3831, -1.2816, -1.1608, -1.4005, -1.4232,\n",
      "         -1.5202, -1.0806, -1.2800, -0.1063, -0.0924, -0.0475, -0.0267, -0.1830,\n",
      "         -1.1417, -1.2547, -0.9999, -1.3233, -1.3158, -1.5344, -1.4522, -1.3633,\n",
      "         -0.8935, -0.9470, -0.6985, -0.4991],\n",
      "        [-1.9340,  1.1721,  1.2102,  1.2436,  1.1821,  1.0594,  2.0391,  2.0767,\n",
      "          2.0660,  2.1233,  2.0658,  0.1394,  0.1353,  0.1267,  0.1139,  0.1313,\n",
      "          1.1905,  1.1870,  0.9181,  0.9991,  0.5428,  0.8797,  0.8632,  0.8429,\n",
      "          0.8089,  0.8303,  1.3195, -1.6789],\n",
      "        [-0.6050,  1.4094,  1.6428,  1.1190,  1.0244,  1.0467, -0.3973, -0.3928,\n",
      "         -0.3424, -0.2666, -0.0103, -0.5800, -0.6179, -0.6923, -0.6950, -0.6545,\n",
      "         -0.7361, -1.1485, -0.8933, -0.0106, -0.4898,  1.4583,  1.9095,  1.8808,\n",
      "          2.0794,  2.2352,  0.3105,  1.5655]])\n",
      "y_pred:  tensor([[2.7476],\n",
      "        [3.1904],\n",
      "        [3.8100]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 0.5116,  6.4189, 12.1446])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.5709,  1.0277,  1.0156,  0.9266,  0.8423,  0.7169, -0.6123, -0.7659,\n",
      "         -0.6413, -0.7515, -0.5765, -0.6502, -0.6530, -0.6574, -0.6598, -0.6195,\n",
      "         -0.5333, -0.6177, -0.7867, -0.6165, -0.2833,  0.3601,  0.4019,  0.4665,\n",
      "          0.3323,  0.2967, -0.6985,  1.5655],\n",
      "        [-0.8812,  0.6976,  0.6696,  0.6775,  0.7574,  0.7549,  1.5195,  1.5259,\n",
      "          1.5386,  1.5518,  1.5339,  2.8764,  2.8681,  2.8452,  2.8396,  2.8204,\n",
      "          0.9877,  1.0808,  0.9181,  0.8981,  0.9558,  0.7356,  0.7661,  0.7872,\n",
      "          0.8771,  0.8926, -0.6985,  0.9756],\n",
      "        [-1.1442, -0.9841, -1.0821, -1.1566, -1.0267, -1.0847, -1.9738, -1.6719,\n",
      "         -1.8191, -1.3230, -1.1599,  0.8236,  0.8535,  0.7541,  0.3250,  0.0789,\n",
      "         -0.8375, -1.2547, -1.2130, -1.1213, -0.1800, -0.4957, -0.8270, -0.8136,\n",
      "         -0.8401, -0.8218, -0.6985, -1.6789]])\n",
      "y_pred:  tensor([[3.1202],\n",
      "        [2.0909],\n",
      "        [2.6761]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.5697, 9.0158, 1.1896])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.0464,  0.5841,  0.6155,  0.6888,  0.6724,  0.6661, -0.0032,  0.1757,\n",
      "          0.1674, -0.0415, -0.0789,  1.5956,  1.5893,  1.5905,  1.7142,  1.6854,\n",
      "         -0.0263, -0.0869, -0.0409,  0.0903,  0.2330,  0.3077,  0.2294,  0.2543,\n",
      "          0.2426,  0.1586,  1.3195,  0.0908],\n",
      "        [ 0.0447,  0.4293,  0.3236,  0.3831,  0.5146,  0.4124, -0.2361, -0.3573,\n",
      "         -0.4479, -0.3705, -0.3878,  0.3324,  0.3455,  0.3707,  0.3777,  0.2535,\n",
      "         -0.1277, -0.0869, -0.4671, -0.5155, -0.4898,  0.1509,  0.1095,  0.0414,\n",
      "          0.2319,  0.1741,  0.3105,  0.3857],\n",
      "        [ 1.1058, -1.2627, -1.1686, -0.9528, -0.7961, -0.2093, -1.5976, -1.4587,\n",
      "         -1.4675, -1.3750, -1.3486, -0.5975, -0.5479, -0.4658, -0.5191, -0.5497,\n",
      "         -0.6347, -0.5116, -0.7867, -1.1213, -0.7996, -0.7600, -0.6102, -0.3054,\n",
      "         -0.2944, -0.2471,  0.3105,  0.0908]])\n",
      "y_pred:  tensor([[1.4561],\n",
      "        [1.4604],\n",
      "        [2.3165]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.5672, 3.0024, 1.3301])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.3079, -2.1499, -2.2282, -2.0171, -2.1675, -2.1631, -0.3257, -0.2684,\n",
      "         -0.2897, -0.6996, -0.8167, -0.0361, -0.1800, -0.0998, -0.0443,  0.0091,\n",
      "         -0.6347,     nan, -0.5736, -0.9194, -0.5930, -1.2446,     nan, -0.9553,\n",
      "         -0.8728, -0.7252, -0.6985,  0.6806],\n",
      "        [ 0.1074,  0.9658,  0.8967,  0.8360,  0.8180,  0.8691,  0.3013,  0.3179,\n",
      "          0.3432,  0.3569,  0.3843,  3.0869,  3.0608,  3.0369,  3.0506,  3.0125,\n",
      "          0.2779,  0.2316,  0.2788,  0.3933,  0.3362,  0.3896,  0.3799,  0.4120,\n",
      "          0.4101,  0.3833,  0.3105, -1.0890],\n",
      "        [-1.1278,  0.7595,  0.7994,  0.7681,  0.8787,  0.9325, -0.1107, -0.1618,\n",
      "         -0.0084, -0.1107, -0.0275, -0.0712,  0.0653,  0.0047,  0.0788,  0.0615,\n",
      "          0.0751,  0.1254,  0.1723, -0.0106, -0.2833,  0.4653,  0.4945,  0.5713,\n",
      "          0.7136,  0.8650, -0.6985,  0.6806]])\n",
      "y_pred:  tensor([[   nan],\n",
      "        [2.0850],\n",
      "        [2.0947]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 2.5676, 19.8350,  8.6224])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.9469,  0.5015,  0.3560,  0.1114,  0.4661,  0.4250,  0.3551,  0.6021,\n",
      "          0.8003,  2.0021,  1.4996, -0.6326, -0.6004, -0.7272, -0.7653, -0.7243,\n",
      "         -1.0403, -0.8300, -1.1064, -1.3233, -1.3158, -0.8978, -0.8508, -0.8902,\n",
      "         -0.7026, -0.6821,  0.3105, -1.3840],\n",
      "        [-0.0907,  0.3984,  0.3236,  0.0548, -0.1650, -0.1078,  0.4626,  0.2290,\n",
      "          0.4487,  0.3049,  0.3157, -0.6853, -0.6530, -0.6226, -0.5543, -0.6719,\n",
      "         -0.6347, -0.5116,  0.7050,  0.7971,  0.6460,  0.5248,  0.2982,  0.3720,\n",
      "          0.2642,  0.3549,  1.3195, -0.7941],\n",
      "        [ 0.1078, -1.2627, -2.1741, -2.4700, -1.9733, -1.4653, -0.0749, -0.3928,\n",
      "         -0.4303, -0.3186, -0.4736,  1.2272,  1.2214,  0.4230,  0.8349,  1.0219,\n",
      "         -0.2291,  0.0192, -0.1474,  0.0903,  0.0265, -0.7890, -0.8477, -1.1371,\n",
      "         -1.5844, -1.7120,  1.3195, -1.3840]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([4.1178, 1.5607, 4.4843])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1470, -2.6039, -2.6499, -2.8096, -3.7331, -3.2415, -1.4005, -1.0146,\n",
      "         -1.2038, -0.6996, -0.9369, -0.1589, -0.1274,  0.0396, -0.0443, -0.5672,\n",
      "          0.5821, -1.4670, -0.6802, -0.5155, -0.6963, -0.4492, -1.0531, -1.4515,\n",
      "         -1.4349, -1.5994,  1.3195, -0.4991],\n",
      "        [-0.5464, -0.3754, -0.4765, -0.2849, -0.4320, -0.0951, -1.1318, -1.1745,\n",
      "         -1.2741, -1.3923, -1.1427, -0.1238, -0.1450, -0.1347, -0.1323, -0.0782,\n",
      "         -0.7361, -0.7239, -0.4671, -0.6165, -0.3865, -0.6413, -0.8122, -0.9177,\n",
      "         -1.0126, -0.9761, -0.6985, -0.4991],\n",
      "        [-0.8811,  0.2127,  0.0533,  0.2473,  0.4297,  0.6027, -0.3794, -0.4994,\n",
      "         -0.4655, -0.5956, -0.6452, -0.5624, -0.4953, -0.5355, -0.6422, -0.6195,\n",
      "         -0.4319, -0.0869, -0.4671, -0.5155, -0.3865, -0.1750, -0.1731, -0.2623,\n",
      "         -0.2783, -0.2135,  0.3105,  1.2705]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.1696, 1.7087, 2.0054])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.3738,  0.5634,  0.6372,  0.5869,  0.5025,  0.6407, -0.2003, -0.2507,\n",
      "         -0.1666, -0.3012, -0.3020, -0.4923, -0.4778, -0.5006, -0.4136, -0.4100,\n",
      "         -0.0263, -0.1931,  0.5985,  0.6962,  0.4395,  0.3249,  0.5652,  0.4955,\n",
      "          0.3819,  0.3526,  0.3105,  0.0908],\n",
      "        [-0.2881, -0.0865, -0.1522, -0.1150, -0.1043, -0.4250, -0.7198, -0.8547,\n",
      "         -0.7995, -0.9074, -0.9712, -0.5273, -0.5654, -0.5703, -0.6246, -0.6894,\n",
      "          0.2779,  0.9747,  0.8116,  1.2010,  0.1297, -0.5337, -0.6691, -0.5242,\n",
      "         -0.5780, -0.8026,  1.3195,  0.3857],\n",
      "        [-0.6179,  0.5634,  0.4966,  0.6435,  0.5632,  0.6027, -0.3973, -0.4461,\n",
      "         -0.6413, -0.6303, -0.5594, -0.6677, -0.6530, -0.6400, -0.6246, -0.6021,\n",
      "          2.0016,  1.5055,  1.9837,  1.3020,  0.9558, -0.3216, -0.3972, -0.3660,\n",
      "         -0.2749, -0.3335,  0.3105, -0.7941]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([3.3658, 1.6460, 3.1795])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.5697,  0.4293,  0.5615,  0.6322,  0.5025,  0.6027, -0.5944, -0.6237,\n",
      "         -0.4830, -0.5437, -0.5079, -0.5975, -0.5829, -0.5703, -0.5543, -0.5148,\n",
      "          0.1765, -0.0869, -0.3605, -0.2126, -0.3865, -0.1417, -0.0767, -0.0259,\n",
      "         -0.2152, -0.2024, -0.6985,  0.3857],\n",
      "        [-0.8155, -0.9944, -0.7793, -0.7490, -0.5777, -0.5265, -0.8094, -0.8725,\n",
      "         -1.0104, -1.0459, -0.8511, -0.4045, -0.3552, -0.2741, -0.3960, -0.2354,\n",
      "         -0.2291, -0.1931,  0.4919,  0.6962,  0.5428, -0.1074, -0.0417,  0.0092,\n",
      "         -0.0849, -0.0756, -0.6985,  0.0908],\n",
      "        [-0.6135, -0.7468, -0.8982, -1.1113, -0.9660, -1.1862, -1.5618, -1.3877,\n",
      "         -1.3796, -1.4616, -1.4516, -0.6677, -0.6179, -0.6226, -0.6246, -0.6195,\n",
      "         -0.5333, -0.2992, -0.2540, -0.4145, -0.6963, -1.0525, -1.0007, -1.0498,\n",
      "         -1.1462, -1.1215,  0.3105, -1.3840]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.8557, 1.6265, 1.9763])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1435e+00,  6.4598e-01,  7.8855e-01,  7.9071e-01,  9.6367e-01,\n",
      "          1.0340e+00,  1.2329e+00,  1.2417e+00,  1.3804e+00,  1.3440e+00,\n",
      "          1.4653e+00,  9.8152e-01,  8.8858e-01,  9.1091e-01,  8.3491e-01,\n",
      "          8.1232e-01, -2.2909e-01, -2.9924e-01, -4.0855e-02, -1.1160e-01,\n",
      "          2.6481e-02, -1.1582e+00, -1.0750e+00, -1.0491e+00, -1.0027e+00,\n",
      "         -9.1346e-01, -1.7075e+00,  3.8570e-01],\n",
      "        [-4.2098e-01,  4.7590e-02, -7.7948e-04, -1.8093e-03,  1.3840e-01,\n",
      "          6.9813e-02, -7.3770e-01, -7.4810e-01, -6.0609e-01, -5.6101e-01,\n",
      "         -4.9074e-01, -4.2208e-01, -4.6028e-01, -5.0061e-01, -4.8395e-01,\n",
      "         -4.7985e-01,  4.8069e-01,  4.4388e-01,  2.7881e-01,  1.9131e-01,\n",
      "         -7.6774e-02, -5.3267e-01, -5.5067e-01, -5.3634e-01, -3.8209e-01,\n",
      "         -4.6147e-01,  1.3195e+00, -7.9409e-01],\n",
      "        [-8.0728e-01,  6.9756e-01,  7.2368e-01,  4.6238e-01,  3.5685e-01,\n",
      "          1.9668e-01, -1.8235e-01, -1.4406e-01, -1.1386e-01, -1.4537e-01,\n",
      "          4.1157e-02, -4.3962e-01, -4.0772e-01, -5.5289e-01, -5.5429e-01,\n",
      "         -6.0208e-01, -5.3328e-01, -6.1772e-01, -6.8019e-01, -1.0203e+00,\n",
      "         -7.9956e-01,  2.2716e-01,  3.2869e-01,  3.3719e-01,  2.6375e-01,\n",
      "          2.2153e-01,  1.3195e+00, -2.0419e-01]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([6.3174, 2.0342, 3.0508])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.4486, -0.2619, -0.5630, -0.6019, -0.5777, -0.2600, -0.5586, -0.6770,\n",
      "         -0.6413, -0.9420, -1.0570, -0.5098, -0.5654, -0.5355, -0.4136, -0.5322,\n",
      "         -0.5333, -0.2992, -0.1474,  0.5952,  0.5428, -0.4018, -0.3970, -0.3839,\n",
      "         -0.2305, -0.3619, -0.6985,  0.9756],\n",
      "        [-0.8700,  0.7491,  0.7561,  0.8247,  0.6967,  0.6280,  0.0505, -0.0019,\n",
      "          0.0444,  0.0278,  0.0240,  0.6131,  0.6433,  0.6321,  0.7118,  0.7425,\n",
      "          0.2779,  0.2316,  0.0657,  0.0903,  0.0265,  0.1024,  0.0834,  0.0699,\n",
      "          0.0182, -0.0308, -0.6985,  0.6806],\n",
      "        [ 0.0459, -0.9635, -1.3307, -1.3944, -0.7597, -0.7168,  0.0326,  0.4955,\n",
      "          1.0640,  1.7943,  1.5511, -0.6677, -0.7055, -0.6574, -0.7126, -0.6021,\n",
      "         -0.8375, -1.4670, -0.8933,  0.8981,  1.7818, -0.2480, -0.2234, -0.0351,\n",
      "         -0.0263, -0.0238, -1.7075,  0.6806]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.3172, 4.2421, 2.0356])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0871, -0.7262, -0.5630, -0.4320, -0.2500, -0.3615, -0.7735, -0.7126,\n",
      "         -0.8170, -0.5610, -0.5251, -0.6853, -0.6705, -0.5703, -0.5543, -0.5497,\n",
      "         -0.6347, -0.9362, -0.9999, -0.7174, -0.7996, -0.8290, -0.8492, -0.9238,\n",
      "         -0.8829, -0.9398, -0.6985, -0.7941],\n",
      "        [ 0.7032,  0.0992,  0.2479,  0.3152,  0.2598, -0.0190, -0.3257, -0.5171,\n",
      "         -0.6764, -0.8727, -1.0570, -0.3344, -0.5128, -0.6052, -0.6246, -0.5148,\n",
      "         -1.2430, -1.2547, -1.2130, -0.9194, -0.4898, -0.7815, -0.7164, -0.9001,\n",
      "         -0.7961, -1.0406,  1.3195,  0.3857],\n",
      "        [ 0.4429, -1.4071, -1.7092, -1.9605, -2.4831, -2.3027, -0.7019, -0.7659,\n",
      "         -0.7995, -0.8208, -0.8682, -0.4923, -0.4778, -0.5006, -0.5015, -0.4624,\n",
      "         -0.6347, -0.6177, -0.0409, -0.0106,  0.0265, -1.2331, -1.2677, -1.2692,\n",
      "         -1.3072, -1.3151, -0.6985, -0.2042]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.4992, 1.9399, 1.7134])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.1062, -1.4174, -1.2118, -0.8396, -1.3301, -1.1862, -0.1465, -0.2151,\n",
      "          0.1498,  0.1144,  0.1956, -0.5800, -0.5654, -0.5355, -0.3257, -0.3576,\n",
      "         -0.0263, -0.8300, -0.3605, -1.0203, -1.0061,  0.1451,  0.0505,  0.2969,\n",
      "          0.5955,  0.4294,  0.3105, -0.7941],\n",
      "        [ 1.0366,  0.1611, -0.0981, -0.3415, -0.0194,  0.0064,  0.1222,  0.1580,\n",
      "          0.3256,  0.0971, -0.1133, -0.2642, -0.3201, -0.4309, -0.2729, -0.2878,\n",
      "         -1.0403, -1.0424,  0.9181,  2.6146,  2.5046,  0.0088, -0.1522, -0.2726,\n",
      "         -0.3947,  0.0076,  1.3195, -1.3840],\n",
      "        [-0.6163, -0.7365, -1.5254, -1.7906, -1.9248, -1.8459, -0.9527, -0.9613,\n",
      "         -1.2214, -1.2711, -1.2972, -0.7379, -0.7756, -0.7446, -0.7301, -0.7069,\n",
      "          2.6100,  2.3548,  2.1968,  1.4030,  0.1297, -1.1172, -1.3542, -1.3232,\n",
      "         -1.0622, -1.1696,  0.3105, -0.7941]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.1975, 9.9241, 0.8006])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.6743, -1.0666, -0.9847, -0.9755, -0.7840, -0.7929, -1.2572, -1.2455,\n",
      "         -1.2390, -1.2884, -1.1427, -0.6853, -0.6880, -0.6923, -0.7126, -0.7942,\n",
      "         -0.8375, -1.0424, -0.6802, -0.9194,  0.1297, -1.3362, -1.2908, -1.1471,\n",
      "         -1.1686, -1.1873, -0.6985, -1.3840],\n",
      "        [-1.2794,  0.7904,  0.7886,  0.8134,  0.8544,  0.8437,  1.7883,  1.8457,\n",
      "          1.8551,  1.8462,  1.8256,  1.6307,  1.6243,  1.5557,  1.5207,  1.5282,\n",
      "          2.6100,  2.7794,  2.8361,  2.6146,  2.8144,  2.1233,  2.2650,  2.3219,\n",
      "          2.4450,  2.2721, -0.6985, -0.2042],\n",
      "        [-0.9444,  0.1198,  0.0425,  0.5303,  0.4175,  0.3743, -0.6123, -0.6060,\n",
      "         -0.6237, -0.4744, -0.2505,  0.2973,  0.3631,  0.4230,  0.3425,  0.3409,\n",
      "          0.4807,  0.8685,  0.9181,  0.6962,  0.6460, -0.1004, -0.0959, -0.2059,\n",
      "         -0.1540,  0.0826,  1.3195,  0.9756]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([ 0.8174, 13.6074,  3.1672])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.8730, -0.1794, -0.5847, -1.4736, -2.5073, -2.9243, -1.0960, -0.9080,\n",
      "         -1.0983, -0.7169, -0.7310,  5.5257,  4.8826,  3.8908,  4.0529,  3.4840,\n",
      "         -1.3444, -1.4670, -1.4261, -0.7174, -0.6963,  1.2825,  1.3227,  1.1109,\n",
      "          1.4199,  0.9014,  1.3195,  0.9756],\n",
      "        [-0.7391,  0.3158,  0.3452,  0.4963,  0.6360,  0.6407,  0.1401,  0.2113,\n",
      "          0.1850,  0.2010,  0.2642, -0.2642, -0.1975, -0.1172, -0.0619, -0.2005,\n",
      "         -0.5333, -0.2992, -0.3605, -0.6165,  0.7493,  0.7151,  0.7428,  0.6388,\n",
      "          0.5798,  0.5570, -0.6985,  0.9756],\n",
      "        [ 0.1086, -0.3445, -0.3360, -0.8396, -0.5655, -0.2093, -0.8273, -0.6060,\n",
      "         -0.7116, -0.4571, -0.6795,  0.1218,  0.1003, -0.3786, -0.3257, -0.3052,\n",
      "         -1.4458, -1.4670, -1.4261, -1.3233, -1.3158, -0.7913, -0.7627, -1.2477,\n",
      "         -1.6080, -0.9818,  1.3195,  0.3857]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([0.8826, 3.2658, 1.6380])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.0440,  0.2436,  0.2804,  0.1454, -0.1529, -0.0571, -0.9885, -0.9613,\n",
      "         -0.9577, -0.6649, -0.7996,  3.3326,  3.3936,  3.6468,  3.3496,  3.1696,\n",
      "         -0.7361,  0.0192, -0.0409,  0.2923,  0.1297,  0.2007,  0.2495,  0.4043,\n",
      "          0.4223,  0.3088,  0.3105,  1.2705],\n",
      "        [-0.5454, -1.6960, -1.4389, -0.9189, -0.8932, -1.3765, -1.0422, -1.0679,\n",
      "         -1.1511, -1.1325, -1.3658, -0.5098, -0.5654, -0.6226, -0.6246, -0.6545,\n",
      "         -0.2291, -0.1931,  0.1723,  0.0903, -0.1800, -1.2796, -1.2141, -1.1233,\n",
      "         -1.0831, -1.2291,  1.3195,  0.9756],\n",
      "        [-0.7457, -0.0762, -0.1413, -0.3075, -0.6019, -0.4504,  0.1580, -0.1263,\n",
      "         -0.0435,  0.0798, -0.0446, -0.3344, -0.3552, -0.3961, -0.3784, -0.2703,\n",
      "         -0.2291, -0.7239, -0.1474, -0.2126, -0.0768,  0.1859,  0.1658,  0.0492,\n",
      "         -0.0077,  0.0378, -0.6985, -0.7941]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.6636, 1.3996, 2.5595])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 1.0364, -1.9745, -2.3580, -3.0700, -3.1142, -3.2669,  0.3730,  0.1224,\n",
      "          0.0971, -0.4225, -0.7138, -0.7203, -0.7581, -0.7097, -0.7126, -0.7069,\n",
      "         -0.9389, -1.4670, -1.4261, -1.3233, -1.3158, -0.8929, -1.3271, -1.4248,\n",
      "         -2.0828, -2.1183, -0.6985, -0.4991],\n",
      "        [-1.8580,  0.5119, -0.0981, -0.4320, -1.0995, -1.2370, -0.6840, -0.7126,\n",
      "         -0.8346, -0.6649, -0.4736,  1.0342,  0.9061,  1.0852,  0.5536,  0.4631,\n",
      "          1.3933,  1.0808,  0.8116,  0.6962, -0.4898,  1.0737,  1.4568,  1.1678,\n",
      "          0.8126,  0.6681,  0.3105, -1.3840],\n",
      "        [-0.8729, -0.1794,  0.0317,  0.1227,  0.1141,  0.2094, -0.8273, -1.0146,\n",
      "         -1.0280, -1.1845, -1.2800, -0.6151, -0.6004, -0.5877, -0.5015, -0.3925,\n",
      "         -0.6347, -0.5116, -0.5736, -0.8184, -0.6963, -0.0037,  0.0369,  0.0224,\n",
      "          0.0188, -0.0106,  1.3195,  0.3857]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.4621, 3.8492, 1.5707])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-1.1397,  2.1935,  2.1510,  2.0814,  2.0195,  2.0109,  3.5080,  3.5513,\n",
      "          3.5955,  3.6127,  3.5757,  1.9640,  2.0973,  2.2179,  2.3824,  2.5061,\n",
      "          4.3337,  4.7965,  4.3279,  4.3311,  4.4664,  3.5546,  3.6634,  3.7887,\n",
      "          3.9471,  4.0397, -0.6985, -0.7941],\n",
      "        [ 0.6435, -0.2929, -0.1738, -0.0131,  0.1384,  0.1206, -0.5944, -0.6060,\n",
      "         -0.5709, -0.4398, -0.4221, -0.4572, -0.4428, -0.4483, -0.4488, -0.4798,\n",
      "         -0.3305, -0.5116, -0.3605, -0.1116,  0.3362, -0.3674, -0.4571, -0.4735,\n",
      "         -0.5145, -0.5530,  0.3105, -0.7941],\n",
      "        [-1.1433,  0.5428,  0.4858,  0.5416,  0.5632,  0.5773, -0.1644, -0.1441,\n",
      "         -0.2369, -0.3532, -0.2505,  1.6131,  1.5367,  1.5208,  1.4504,  1.4060,\n",
      "          0.5821,  0.6562,  0.4919,  0.4942,  0.2330, -0.4310, -0.4255, -0.3973,\n",
      "         -0.3813, -0.4064, -0.6985, -0.2042]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([10.3151,  1.3865,  4.0233])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-7.3966e-01,  7.8541e-02,  8.5723e-02,  1.1141e-01,  4.4181e-01,\n",
      "          1.5862e-01, -4.6898e-01, -3.7502e-01, -3.7755e-01,  1.3172e-01,\n",
      "          2.1274e-01, -4.5717e-01, -4.0772e-01, -4.3091e-01, -5.3671e-01,\n",
      "         -4.9731e-01, -1.0403e+00, -9.3621e-01, -6.8019e-01, -1.0203e+00,\n",
      "         -1.1093e+00, -1.6517e-01, -2.9839e-01, -2.5375e-01, -3.1885e-01,\n",
      "         -3.8221e-01,  3.1046e-01,  1.5655e+00],\n",
      "        [-1.4706e-01, -3.9952e-03, -1.1972e-01, -9.2383e-02, -1.6501e-01,\n",
      "         -2.8542e-01, -9.2773e-02, -1.9324e-03,  9.2021e-03,  7.9763e-02,\n",
      "          5.8315e-02, -6.1507e-01, -4.7779e-01, -5.0061e-01, -4.6637e-01,\n",
      "         -4.2746e-01, -6.3467e-01, -7.2388e-01, -8.9330e-01, -8.1840e-01,\n",
      "         -7.9956e-01, -6.1918e-01, -6.2563e-01, -5.9135e-01, -5.5558e-01,\n",
      "         -4.8749e-01,  3.1046e-01, -1.3840e+00],\n",
      "        [-7.4811e-01, -3.8572e-01,  8.5723e-02,  3.2156e-02,  1.5053e-01,\n",
      "          2.4743e-01, -6.8395e-01, -8.1916e-01, -6.4125e-01, -6.4760e-01,\n",
      "         -3.7064e-01,  1.8763e+00,  2.1148e+00,  2.1482e+00,  2.3648e+00,\n",
      "          2.1219e+00,  1.7650e-01, -4.0540e-01, -1.4741e-01, -2.1257e-01,\n",
      "         -7.9956e-01,  1.0091e-01,  1.4662e-01,  1.5918e-01, -1.3277e-02,\n",
      "         -1.7418e-01, -6.9854e-01,  1.5655e+00]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([2.4836, 2.4025, 1.3434])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[-0.0887, -0.5508, -0.6063, -0.5679, -0.6626, -0.3996, -0.5048, -0.4105,\n",
      "         -0.4655, -0.4917, -0.3363, -0.6677, -0.6004, -0.5355, -0.6422, -0.6719,\n",
      "         -0.1277,  0.0192,  0.3854,  0.5952,  1.3688, -0.4708, -0.6907, -0.1882,\n",
      "         -0.2479, -0.2119, -1.7075,  0.6806],\n",
      "        [-0.1530,  0.2127,  0.3344,  0.3605,  0.4904,  0.5139, -0.1823, -0.1796,\n",
      "         -0.1666, -0.0415,  0.0412, -0.2291, -0.2150, -0.1695, -0.2378, -0.2354,\n",
      "         -0.3305, -0.2992, -0.1474, -0.2126, -0.2833,  0.0387, -0.0336, -0.1298,\n",
      "         -0.0900, -0.2028,  0.3105,  0.9756],\n",
      "        [-0.3547,  0.8214,  0.7669,  0.7567,  0.6603,  0.6154,  0.6059,  0.6732,\n",
      "          0.7124,  0.7032,  0.6932,  1.4026,  1.4316,  1.3814,  1.4152,  1.4759,\n",
      "          0.4807,  0.4439,  0.4919,  0.3933,  0.4395,  0.9708,  1.0634,  1.1000,\n",
      "          1.1206,  1.0323, -0.6985,  0.3857]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([1.2802, 2.4903, 5.0736])\n",
      "Epoch 0: accuracy=0.000, loss=nan, SMAPE=nan\n",
      "X_batch:  tensor([[ 0.5099,  0.7904,  0.7994,  0.6435,  0.0534, -0.3869,  0.8388,  1.0285,\n",
      "          1.2222,  1.1535,  1.2422, -0.5273, -0.5479, -0.5006, -0.5367, -0.5322,\n",
      "         -0.5333, -1.2547, -1.3195, -1.1213, -1.2126,  0.8518,  0.8232,  0.7726,\n",
      "          0.8579,  0.9565, -1.7075,  0.9756],\n",
      "        [-0.9474,  1.3372,  1.1886,  1.3228,  1.1943,  1.1228,  0.2655,  0.0691,\n",
      "          0.1147, -0.3705, -0.3192, -0.3694, -0.3201, -0.3089, -0.0092, -0.0608,\n",
      "         -1.3444, -1.3608, -0.9999, -0.7174, -0.5930,  0.6841,  0.5851,  0.3918,\n",
      "          0.2087,  0.4681,  0.3105,  0.3857],\n",
      "        [-0.0891, -0.2000, -0.1522, -0.0358,  0.3326,  0.6027,  0.1222,  0.0869,\n",
      "          0.2026,  0.1664,  0.1784, -0.5449, -0.4953, -0.5355, -0.5191, -0.5497,\n",
      "          0.6835,  0.3377,  1.0247,  0.5952,  0.7493,  0.2600,  0.2757,  0.2426,\n",
      "          0.3273,  0.3563, -1.7075,  0.9756]])\n",
      "y_pred:  tensor([[nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<SliceBackward0>)\n",
      "y_batch:  tensor([4.3610, 2.0350, 2.1263])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 100>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    122\u001b[0m val_smape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[0;32m    124\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m    125\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PATH = '/Users/dh/Desktop/상진/kaggle/'\n",
    "\n",
    "# Load the train, test, and census datasets\n",
    "train_df = pd.read_csv(PATH+'train.csv')\n",
    "test_df = pd.read_csv(PATH+'test.csv')\n",
    "census_df = pd.read_csv(PATH+\"census_starter.csv\")\n",
    "\n",
    "# Merge the train and test datasets with the census dataset on the \"cfips\" column\n",
    "train_df = pd.merge(train_df, census_df, on=\"cfips\", how=\"left\")\n",
    "test_df = pd.merge(test_df, census_df, on=\"cfips\", how=\"left\")\n",
    "\n",
    "train_df['first_day_of_month'] = pd.to_datetime(train_df['first_day_of_month'])\n",
    "train_df['year'] = train_df['first_day_of_month'].dt.year\n",
    "train_df['month'] = train_df['first_day_of_month'].dt.month\n",
    "test_df['first_day_of_month'] = pd.to_datetime(test_df['first_day_of_month'])\n",
    "test_df['first_day_of_month'] = pd.to_datetime(test_df['first_day_of_month'])\n",
    "test_df['year'] = test_df['first_day_of_month'].dt.year\n",
    "test_df['month'] = test_df['first_day_of_month'].dt.month\n",
    "train_df = train_df.drop(columns=['row_id', 'county', 'state', 'active', 'first_day_of_month'])\n",
    "test_df = test_df.drop(columns=['row_id', 'first_day_of_month'])\n",
    "\n",
    "# Separate the features and target columns\n",
    "features = list(test_df.columns)\n",
    "target = train_df['microbusiness_density']\n",
    "train_df = train_df.drop(columns=['microbusiness_density'])\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_df[features] = scaler.fit_transform(train_df[features])\n",
    "test_df[features] = scaler.transform(test_df[features])\n",
    "\n",
    "# Convert the data to tensors and create PyTorch dataloaders for training and validation\n",
    "X_train_ = torch.Tensor(train_df[features].values)\n",
    "y_train_ = torch.Tensor(target.values)\n",
    "X_test = torch.Tensor(test_df[features].values)\n",
    "\n",
    "# Split the train dataset into a training and validation set\n",
    "split_index = int(len(train_df) * 0.8)\n",
    "X_train, y_train = X_train_[:split_index], y_train_[:split_index]\n",
    "X_val, y_val = X_train_[split_index:], y_train_[split_index:]\n",
    "\n",
    "# Create PyTorch dataloaders for the training and validation sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# # Choose an appropriate model and a loss function\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(X_train.shape[1], 256),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(256, 128),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(128, 1)\n",
    "# )\n",
    "\n",
    "# Define the model architecture\n",
    "class MicrobusinessModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MicrobusinessModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "input_size = len(train_dataset[0][0])  # size of the input data\n",
    "hidden_size = 128  # size of the hidden layer\n",
    "output_size = 1  # size of the output (microbusiness density)\n",
    "\n",
    "model = MicrobusinessModel(input_size, hidden_size, output_size)\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Check if the validation dataloader has any data\n",
    "if len(val_dataloader) == 0:\n",
    "    print(\"Warning: validation set is empty\")\n",
    "else:\n",
    "    # Train the model on the training data and evaluate its performance on the validation data\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_dataloader:\n",
    "            print(\"X_batch: \", X_batch[:3])\n",
    "            y_pred = model(X_batch)\n",
    "            print(\"y_pred: \", y_pred[:3])\n",
    "            print(\"y_batch: \", y_batch[:3])\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                # Evaluate the model's performance on the validation data\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                val_accuracy = 0\n",
    "                val_smape = 0\n",
    "                for X_batch, y_batch in val_dataloader:\n",
    "                    y_pred = model(X_batch)\n",
    "                    val_loss += loss_fn(y_pred, y_batch).item()\n",
    "                    val_accuracy += (y_pred.round() == y_batch).float().mean().item()\n",
    "                    val_smape += ((y_pred - y_batch).abs() / (y_pred + y_batch).abs()).mean().item()\n",
    "                val_loss /= len(val_dataloader)\n",
    "                val_accuracy /= len(val_dataloader)\n",
    "                val_smape /= len(val_dataloader)\n",
    "\n",
    "                # Print the accuracy, loss, and SMAPE values on the validation data\n",
    "                print(f\"Epoch {epoch}: accuracy={val_accuracy:.3f}, loss={val_loss:.3f}, SMAPE={val_smape:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7574918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 28))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set and create a submission CSV file\n",
    "y_pred = model(X_test).flatten().round().numpy()\n",
    "submission_df = pd.DataFrame({\"row_id\": test_df[\"row_id\"], \"microbusiness_density\": y_pred})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# Render various and relevant visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Line plot of the predicted and actual values\n",
    "plt.plot(y_test.numpy(), label=\"Actual\")\n",
    "plt.plot(y_pred, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of the predicted values against the actual values\n",
    "plt.scatter(y_test.numpy(), y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram of the prediction errors\n",
    "errors = y_pred - y_test.numpy()\n",
    "plt.hist(errors, bins=50)\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09013ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c102681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a460460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train.values)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val.values)\n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "# Create PyTorch data loaders\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_data = TensorDataset(X_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Choose the input and output sizes based on the data\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 1\n",
    "\n",
    "# Choose the hidden size based on the complexity of the problem\n",
    "hidden_size = 128\n",
    "\n",
    "# Create the model\n",
    "model = Net(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Choose a loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Choose an optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "def smape(y_pred, y_true):\n",
    "    numerator = torch.abs(y_pred - y_true)\n",
    "    denominator = torch.abs(y_pred) + torch.abs(y_true)\n",
    "    return 100 * torch.mean(numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    # Loop over the train data\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        y_batch = y_batch.view(-1, 1)\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_val)\n",
    "        val_loss = loss_fn(y_pred, y_val)\n",
    "        val_smape = smape(y_pred, y_val)\n",
    "    \n",
    "    # Print the loss and SMAPE every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1} - Loss: {val_loss:.4f}, SMAPE: {val_smape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fd772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "\n",
    "# Convert the predictions to a numpy array\n",
    "y_pred = y_pred.numpy().flatten()\n",
    "\n",
    "# Get the row IDs from the test set\n",
    "row_ids = test_df[\"row_id\"]\n",
    "\n",
    "# Create a dataframe with the predictions\n",
    "prediction_df = pd.DataFrame({\"row_id\": row_ids, \"microbusiness_density\": y_pred})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "prediction_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the ground truth values from the train set\n",
    "y_true = train_df[\"microbusiness_density\"].values\n",
    "\n",
    "# Plot the predictions and ground truth values\n",
    "plt.plot(y_pred, label=\"Predictions\")\n",
    "plt.plot(y_true, label=\"Ground truth\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe3bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabaaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f279a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Define a function to compute the SMAPE metric\n",
    "def smape(y_pred, y_true):\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    numerator = np.abs(y_pred.detach().numpy() - y_true.detach().numpy())\n",
    "    denominator = np.abs(y_pred.detach().numpy()) + np.abs(y_true.detach().numpy())\n",
    "    return 100 * np.mean(numerator / denominator)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # Loop over the batches in the train dataloader\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        # Convert the data to tensors and move to the GPU if available\n",
    "        X_batch = torch.tensor(X_batch, dtype=torch.float).to(device)\n",
    "        y_batch = torch.tensor(y_batch, dtype=torch.float).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        y_batch = y_batch.view(-1, 1)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print the loss and SMAPE every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {loss.item():.4f} - SMAPE: {smape(y_pred, y_batch):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = []\n",
    "for X_batch in test_dataloader:\n",
    "    # Convert the data to a tensor and move to the GPU if available\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float).to(device)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model(X_batch)\n",
    "    \n",
    "    # Convert the predictions back to numpy arrays and append to the list\n",
    "    predictions.append(y_pred.cpu().numpy())\n",
    "\n",
    "# Concatenate the predictions into a single array\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# Create a DataFrame with the row IDs and predictions\n",
    "submission_df = pd.DataFrame({'row_id': test_df['row_id'], 'microbusiness_density': predictions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv(PATH+'submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47851cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PATH = '/Users/dh/Desktop/상진/kaggle/'\n",
    "\n",
    "# # Load and prepare the data\n",
    "# train_df = pd.read_csv(PATH+'train.csv')\n",
    "# test_df = pd.read_csv(PATH+'test.csv')\n",
    "# census_df = pd.read_csv(PATH+'census_starter.csv')\n",
    "\n",
    "# # Merge train and census data\n",
    "# train_df = train_df.merge(census_df, on='cfips')\n",
    "\n",
    "# # preprocessing\n",
    "# train_df['county'] = train_df['county'].astype('category').cat.codes\n",
    "# train_df['state'] = train_df['state'].astype('category').cat.codes\n",
    "# train_df['first_day_of_month'] = pd.to_datetime(train_df['first_day_of_month'])\n",
    "# train_df['year'] = train_df['first_day_of_month'].dt.year\n",
    "# train_df['month'] = train_df['first_day_of_month'].dt.month\n",
    "# train_df = train_df.drop(['first_day_of_month'], axis=1)\n",
    "\n",
    "# test_df['first_day_of_month'] = pd.to_datetime(test_df['first_day_of_month'])\n",
    "# test_df['year'] = test_df['first_day_of_month'].dt.year\n",
    "# test_df['month'] = test_df['first_day_of_month'].dt.month\n",
    "# test_df = test_df.drop(['first_day_of_month'], axis=1)\n",
    "\n",
    "# # Select the features and target for the model\n",
    "# X_train = train_df.drop(['row_id', 'microbusiness_density'], axis=1)\n",
    "# y_train = train_df['microbusiness_density']\n",
    "# X_test = test_df.drop(['row_id'], axis=1)\n",
    "\n",
    "# # Scale the data using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Convert data to tensors\n",
    "# X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "# y_train = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
    "# X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "\n",
    "# # Split the train data into train and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# # Create the model\n",
    "# class MicrobusinessModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(MicrobusinessModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "#         self.relu = nn.ReLU()\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "# hidden_dim = 64\n",
    "# output_dim = 1\n",
    "# model = MicrobusinessModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# # Choose the loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Forward pass\n",
    "#     y_pred = model(X_train)\n",
    "#     loss = criterion(y_pred, y_train)\n",
    "    \n",
    "#     # Backward pass\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Print accuracy and loss every 10 epochs\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model on the validation set\n",
    "# with torch.no_grad():\n",
    "#     y_val_pred = model(X_val)\n",
    "#     val_loss = criterion(y_val_pred, y_val)\n",
    "#     print(f'Validation Loss: {val_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e30624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on the test set\n",
    "# with torch.no_grad():\n",
    "#     y_test_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the submission file\n",
    "# submission_df = pd.DataFrame({'row_id': test_df['row_id'], 'microbusiness_density': y_test_pred.numpy().flatten()})\n",
    "# submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
